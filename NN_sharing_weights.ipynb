{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikiska77/ydata-viz-ai/blob/main/NN_sharing_weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#install packages"
      ],
      "metadata": {
        "id": "gemzh1fLMQbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install wget\n",
        "!pip install -U git+https://github.com/pydicom/pydicom.git\n",
        "#pip install --no-cache-dir git+https://github.com/pydicom/pydicom.git\n",
        "!pip install python-gdcm\n",
        "\n",
        "!pip install torchsummary \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbCGtqQV1Rtj",
        "outputId": "d2cc200f-50a2-4fb9-ff31-3917ec794f56"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=254e60ddfbe88cc8ba351877a243241d98a9b850947f03dcdfbce236c944f7ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting git+https://github.com/pydicom/pydicom.git\n",
            "  Cloning https://github.com/pydicom/pydicom.git to /tmp/pip-req-build-gp118jpy\n",
            "  Running command git clone -q https://github.com/pydicom/pydicom.git /tmp/pip-req-build-gp118jpy\n",
            "Building wheels for collected packages: pydicom\n",
            "  Building wheel for pydicom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydicom: filename=pydicom-2.4.0.dev0-py3-none-any.whl size=1964280 sha256=f5fe13450e654d26f0ddda73843651939e4d4210aed928d915c7005a5c238ebc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h6pyfvnq/wheels/8a/75/6f/a3a81ff6d9eaa04f50d99238b899485b32c5948527a33b243c\n",
            "Successfully built pydicom\n",
            "Installing collected packages: pydicom\n",
            "Successfully installed pydicom-2.4.0.dev0\n",
            "Collecting python-gdcm\n",
            "  Downloading python_gdcm-3.0.12-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.6 MB 28.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: python-gdcm\n",
            "Successfully installed python-gdcm-3.0.12\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dicom_utils as dcm\n",
        "import Affine3D as affine\n",
        "from scipy.ndimage import affine_transform"
      ],
      "metadata": {
        "id": "4Dbj-djYS9yZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOK-xRF0wwQ-"
      },
      "outputs": [],
      "source": [
        "#input_file = \"/Users/boriskefer/Documents/coding/YDATA/2021_2022_main/viz_ai/ydata-viz-ai/YdataDataset.txt\" \n",
        "#data_path = \"/Users/boriskefer/Documents/coding/YDATA/2021_2022_main/viz_ai/ydata-viz-ai/data03_01\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to work from Colab and google disk:\n",
        "from google.colab import drive \n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "home_path = Path(\"/content/drive/MyDrive/VIZ/data/data03_01\")\n",
        "#data_path = os.path.join(home_path, \"data\")\n",
        "#print(data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2wJJnaL1YAl",
        "outputId": "ac77516b-5f9e-49c3-80a9-705c6c64de12"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "import copy\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "from torchvision.utils import make_grid"
      ],
      "metadata": {
        "id": "36mYe5v4MY1D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "2fA5q8_YMVBl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8FCRXh0wwQ4"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(1,3,64,64) # input x\n",
        "y = torch.rand(1,3,64,64) # input y\n",
        "cnn = nn.Conv2d(3,10,kernel_size=5) # network\n",
        "input = torch.cat((x,y),dim=0) # stack them batch-wise\n",
        "output = cnn(input) # pass both x and y through the network as a single pass\n",
        "x_out = output[0] # get the output of x\n",
        "y_out = output[1] # get the output of y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variant 1 (concatenating the input)"
      ],
      "metadata": {
        "id": "BzjKhpWicQhp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wZCAzD0lwwQ9"
      },
      "outputs": [],
      "source": [
        "class Our_AirNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Our_AirNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.firstlayer = nn.Sequential(\n",
        "            #how many channels do we have?? \n",
        "            nn.Conv2d(in_channels=20,out_channels=20,kernel_size=3,stride=1,padding=1),\n",
        "            #(320 - 3 + 2*1)/1 + 1 = 320\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n",
        "            #(320 - 2)/2 + 1 = 160\n",
        "        self.transition = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=20,out_channels=20,kernel_size=1,stride=1,padding=0),\n",
        "            #(160 - 1 )/1 + 1 \n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n",
        "            #80\n",
        "        self.regression = nn.Sequential(\n",
        "            #we have to double here because the images will be concatenated\n",
        "            nn.Linear(20*20*20*2, 1024),\n",
        "            #nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "           # nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 128),\n",
        "           # nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 64),\n",
        "           # nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(64, 12))    \n",
        "        \n",
        "    def forward(self, x, y):\n",
        "        inp = torch.cat((x,y),dim=0) # stack them batch-wise\n",
        "        inp = self.firstlayer(inp)\n",
        "        inp = self.transition(inp) #80\n",
        "        inp = self.transition(inp) #40\n",
        "        inp = self.transition(inp) #20\n",
        "        input_conc = torch.cat((inp[:inp.shape[0]].flatten(),inp[inp.shape[0]:].flatten()),dim=0)\n",
        "        #inp = self.flatten(inp)\n",
        "        res = self.regression(input_conc)\n",
        "        return res        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Our_AirNet()\n",
        "summary(model, (20, 320, 320), batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "iHI1JBtB8fId",
        "outputId": "070398a1-2415-45d7-ba74-93799e91d0f5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-f2fd710d0d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOur_AirNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'y'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a = torch.rand(1,3,5,5) # input a\n",
        "print(a.shape)\n",
        "b = torch.rand(1,3,5,5) # input b\n",
        "print(b.shape)\n",
        "c = torch.cat((a,b),dim=0) # stack them batch-wise\n",
        "n=a.shape[0]\n",
        "c.shape\n",
        "\n",
        "d = torch.cat((c[:a.shape[0]].flatten(),c[a.shape[0]:].flatten()),dim=0)\n",
        "d.shape\n",
        "#print(input_conc)\n",
        "c[:a.shape[0]].shape\n",
        "\n",
        "a = a.flatten()\n",
        "a.shape\n",
        "b = b.flatten()\n",
        "c.shape\n",
        "c = torch.cat((a,b), dim=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMzcKQoTeQW_",
        "outputId": "0dc4bce7-cd13-4203-b1d6-b6bfd713e72d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([150])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bjC9MK0fwwQ_"
      },
      "outputs": [],
      "source": [
        "def normalize(img, min_val, max_val):\n",
        "    return (img - min_val) / (max_val - min_val)\n",
        "\n",
        "def transform(img):\n",
        "    alpha = np.random.randint(-45, 45)\n",
        "    m = affine.Affine3dRotateCenterMatrix(alpha, img.shape, axis=2)\n",
        "    return affine.affine_transform(img, m), m\n",
        "\n",
        "class Img3dDataSet(Dataset):\n",
        "    def __init__(self, data_path, min_val, max_val):\n",
        "        self.d_path = data_path\n",
        "        self.min_val = min_val\n",
        "        self.max_val = max_val\n",
        "        self.transform = None\n",
        "        self.target_transform = None\n",
        "        names = [f for f in os.listdir(data_path) if f.endswith(\".npz\")]\n",
        "        self.names_array = np.sort(np.array(names))\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        name = self.names_array[idx]\n",
        "        img3d = np.load(os.path.join(self.d_path, name))['I']\n",
        "        img3d = normalize(img3d, self.min_val, self.max_val)\n",
        "        label, matrix = transform(img3d)\n",
        "        print(label.shape, matrix.shape)\n",
        "        matrix = matrix[:3,:]\n",
        "        print(matrix)\n",
        "        label = label.transpose(2, 0, 1)\n",
        "        label = torch.from_numpy(label).float()\n",
        "        #adding this to get the dimensions nedded\n",
        "        img3d = img3d.transpose(2, 0, 1)\n",
        "        #print(img3d.shape , label.shape)\n",
        "        item = torch.from_numpy(img3d).float()\n",
        "        return item, label, matrix\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.names_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eOcq93w8wwRA"
      },
      "outputs": [],
      "source": [
        "dataset = Img3dDataSet(home_path, -1000, 1000)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "88X6iI6_wwRB",
        "outputId": "c07cd526-1293-4a8b-e527-74fc4e410f16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(320, 320, 20) (4, 4)\n",
            "[[  0.9612617   -0.27563736   0.          50.300106  ]\n",
            " [  0.27563736   0.9612617    0.         -37.903847  ]\n",
            " [  0.           0.           1.           0.        ]]\n",
            "CPU times: user 968 ms, sys: 12.4 ms, total: 980 ms\n",
            "Wall time: 1.68 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "x, y, matrix = next(iter(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape, y.shape, matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cwoVEPVGreP",
        "outputId": "e032e704-2515-481a-f223-b36983519971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  0.7880,  -0.6157,   0.0000, 132.4241],\n",
              "         [  0.6157,   0.7880,   0.0000, -64.5876],\n",
              "         [  0.0000,   0.0000,   1.0000,   0.0000],\n",
              "         [  0.0000,   0.0000,   0.0000,   1.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix1 = matrix[:,:3,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHu9dBlCIEao",
        "outputId": "ac349b39-6f52-4167-e75e-40956ca4062d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  0.7880,  -0.6157,   0.0000, 132.4241],\n",
              "         [  0.6157,   0.7880,   0.0000, -64.5876],\n",
              "         [  0.0000,   0.0000,   1.0000,   0.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7eBwN8ewwRC",
        "outputId": "8414c507-0877-43fa-f1f9-18e98a5e63b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9f627ecc10>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(x[0][:,:,10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAsWhP3EwwRD",
        "outputId": "001fc023-3812-4c12-ac3e-b13557912725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9f62352c10>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(y[0][:,:,10])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running model"
      ],
      "metadata": {
        "id": "Pb-tzRrd23jO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qkJ5v4gWwwRD"
      },
      "outputs": [],
      "source": [
        "model = Our_AirNet()\n",
        "model.train()\n",
        "criterion = nn.MSELoss(reduction='sum')\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.005 )\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.8)\n",
        "num_epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RA00bOVewwRD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5c50c3c5-1283-4ef4-f947-c40515b4e6cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0384, -0.1163,  0.0089,  0.1151,  0.1330, -0.0182, -0.1301,  0.0335,\n",
            "        -0.0734,  0.1155, -0.0432,  0.0513], grad_fn=<AddBackward0>)\n",
            "Epoch number 0\n",
            " Current loss 3960.75439453125\n",
            "\n",
            "tensor([ 26.1994,   7.0512, -13.6734,  21.8267,  21.3913,  -0.1400,  14.3521,\n",
            "        -31.3906,  12.6871,   5.7398,   9.6353,  -4.8837],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 1\n",
            " Current loss 2676.16357421875\n",
            "\n",
            "tensor([ 3.7846,  1.8442,  1.8124, 11.3644, -6.7835,  0.1002,  6.9635, -6.3166,\n",
            "        -6.5137, -7.2562, -2.3690, -2.6669], grad_fn=<AddBackward0>)\n",
            "Epoch number 2\n",
            " Current loss 2742.09716796875\n",
            "\n",
            "tensor([ 20.9561,  -2.7864,   3.2731,  50.9372, -26.9761,  -2.8917,  19.2538,\n",
            "        -47.4532, -23.7333, -21.5848, -15.3128,  -7.7933],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 3\n",
            " Current loss 2992.63330078125\n",
            "\n",
            "tensor([  8.2895,  -2.4096,  -0.4962,  17.2140,  -0.2176,  -1.8884,   1.9624,\n",
            "        -19.0680,  -3.6148,  -1.9223,  -4.7435,  -1.2717],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 4\n",
            " Current loss 1571.5643310546875\n",
            "\n",
            "tensor([ 10.5231,  -2.8181,  -2.3835,  19.0973,   6.8137,  -2.4876,  -2.8805,\n",
            "        -23.5487,  -0.1255,   3.4012,  -3.1971,   2.0121],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 5\n",
            " Current loss 1379.4459228515625\n",
            "\n",
            "tensor([ 14.4176,  -5.4894,  -6.4834,  39.8043,  15.9537,  -4.7773,  -8.0953,\n",
            "        -47.2675,   2.8192,   9.5971,  -5.1455,   7.2506],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 6\n",
            " Current loss 982.7862548828125\n",
            "\n",
            "tensor([  6.0192,   0.2495,  -4.1323,  42.0949,   6.3307,  -3.5014,  -1.8058,\n",
            "        -43.1636,   1.4310,   9.1610,  -3.6330,   4.6471],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 7\n",
            " Current loss 326.795166015625\n",
            "\n",
            "tensor([ -2.4726,   3.0819,  -0.8460,  49.8251,  -1.9972,  -1.5606,   3.0759,\n",
            "        -41.8938,  -0.2490,   7.0850,  -1.4584,   2.5413],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 8\n",
            " Current loss 123.67467498779297\n",
            "\n",
            "tensor([ -6.9863,   1.0053,   2.7946,  42.3999,  -5.8967,   1.5154,   3.3162,\n",
            "        -29.8642,  -1.7560,   1.9920,   1.3032,  -0.1720],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 9\n",
            " Current loss 256.2396240234375\n",
            "\n",
            "tensor([-12.0570,   0.1837,   5.4645,  62.7913,  -8.9914,   5.3963,   3.2404,\n",
            "        -40.3401,  -2.0701,  -1.1738,   3.5439,  -3.2226],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 10\n",
            " Current loss 500.079833984375\n",
            "\n",
            "tensor([ -6.5871,  -0.4661,   3.3030,  43.4424,  -3.8384,   4.9994,  -0.1943,\n",
            "        -27.2582,  -0.7940,  -1.6788,   2.6364,  -2.8090],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 11\n",
            " Current loss 275.5676574707031\n",
            "\n",
            "tensor([-3.8246e+00, -2.9355e-01,  2.0532e+00,  4.2562e+01, -1.0189e+00,\n",
            "         5.3676e+00, -2.3009e+00, -2.7144e+01,  2.2701e-02, -1.5881e+00,\n",
            "         2.3385e+00, -2.4600e+00], grad_fn=<AddBackward0>)\n",
            "Epoch number 12\n",
            " Current loss 239.53839111328125\n",
            "\n",
            "tensor([ -1.7751,   0.3882,   0.7998,  56.3935,   1.6765,   6.6757,  -4.8108,\n",
            "        -37.1244,   1.2637,  -1.6765,   2.4929,  -2.2760],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 13\n",
            " Current loss 115.88201141357422\n",
            "\n",
            "tensor([  1.0479,   1.2626,  -0.8743,  59.7681,   3.7872,   5.5773,  -5.7083,\n",
            "        -40.6071,   2.0980,  -1.3509,   1.9293,  -0.6058],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 14\n",
            " Current loss 173.7691192626953\n",
            "\n",
            "tensor([  2.4134,   1.4442,  -1.4204,  46.6866,   3.4753,   2.7121,  -4.0723,\n",
            "        -32.5933,   1.8176,  -0.9691,   1.0631,   1.2596],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 15\n",
            " Current loss 84.06320190429688\n",
            "\n",
            "tensor([  2.8991,   1.5182,  -1.7581,  43.8022,   3.0663,   1.1812,  -3.0157,\n",
            "        -31.1650,   1.8700,  -1.0071,   0.8276,   2.1142],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 16\n",
            " Current loss 123.64137268066406\n",
            "\n",
            "tensor([ 3.6447e+00,  1.4155e+00, -2.4044e+00,  5.0460e+01,  2.9830e+00,\n",
            "         1.3870e-02, -2.0324e+00, -3.6677e+01,  2.5468e+00, -1.3106e+00,\n",
            "         9.2157e-01,  2.6484e+00], grad_fn=<AddBackward0>)\n",
            "Epoch number 17\n",
            " Current loss 44.95492935180664\n",
            "\n",
            "tensor([  3.9865,   0.7676,  -2.4784,  56.4598,   2.4751,  -0.9048,  -0.5842,\n",
            "        -41.9413,   3.0569,  -1.5109,   1.2777,   2.7884],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 18\n",
            " Current loss 98.7665786743164\n",
            "\n",
            "tensor([  3.2481,  -0.2760,  -1.3929,  51.2002,   1.4681,  -0.9137,   1.1112,\n",
            "        -38.8238,   2.7260,  -1.1763,   1.5316,   2.0877],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 19\n",
            " Current loss 28.453838348388672\n",
            "\n",
            "tensor([  2.1741,  -0.7386,   0.2657,  45.0547,   0.8609,  -0.1733,   2.2513,\n",
            "        -34.2993,   1.7924,  -0.9694,   1.2946,   1.1739],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 20\n",
            " Current loss 54.57844161987305\n",
            "\n",
            "tensor([  1.4577,  -0.9142,   1.6850,  46.2613,   0.4504,   0.5376,   2.8857,\n",
            "        -35.1140,   0.9581,  -0.9150,   1.1922,   0.6296],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 21\n",
            " Current loss 38.31470489501953\n",
            "\n",
            "tensor([  0.9624,  -0.9930,   2.8854,  52.5636,   0.0651,   1.2145,   3.2207,\n",
            "        -39.7577,   0.1168,  -0.8242,   1.2269,   0.1382],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 22\n",
            " Current loss 28.645021438598633\n",
            "\n",
            "tensor([  0.7003,  -0.9499,   3.1873,  54.4601,  -0.3121,   1.4845,   2.7926,\n",
            "        -41.1692,  -0.6517,  -0.3386,   1.3296,  -0.2911],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 23\n",
            " Current loss 47.8001708984375\n",
            "\n",
            "tensor([  0.6988,  -0.7869,   2.4935,  49.2959,  -0.5324,   1.2340,   1.8103,\n",
            "        -37.3453,  -1.0210,   0.3149,   1.4098,  -0.4653],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 24\n",
            " Current loss 13.398571014404297\n",
            "\n",
            "tensor([  0.8795,  -0.6636,   1.5708,  45.9239,  -0.6850,   0.8052,   0.9107,\n",
            "        -34.9355,  -1.1170,   0.8234,   1.6021,  -0.4012],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 25\n",
            " Current loss 34.81227111816406\n",
            "\n",
            "tensor([  1.2111,  -0.6235,   0.6803,  48.4579,  -0.8669,   0.3605,   0.1590,\n",
            "        -37.0410,  -1.1685,   1.2219,   2.0174,  -0.1903],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 26\n",
            " Current loss 10.405807495117188\n",
            "\n",
            "tensor([ 1.5272e+00, -5.1478e-01, -1.6993e-01,  5.2944e+01, -9.2343e-01,\n",
            "         3.3600e-02, -5.5918e-01, -4.0511e+01, -1.2318e+00,  1.4672e+00,\n",
            "         2.3748e+00,  8.6724e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 27\n",
            " Current loss 22.37611198425293\n",
            "\n",
            "tensor([  1.5056,  -0.2050,  -0.6864,  52.6588,  -0.6020,   0.1366,  -1.0016,\n",
            "        -40.0764,  -1.2372,   1.3857,   2.1265,   0.1402],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 28\n",
            " Current loss 18.248689651489258\n",
            "\n",
            "tensor([  1.2003,   0.1187,  -0.8428,  48.6624,  -0.0836,   0.5757,  -1.0441,\n",
            "        -36.7383,  -1.1260,   1.0869,   1.4212,  -0.1150],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 29\n",
            " Current loss 8.971309661865234\n",
            "\n",
            "tensor([  0.8947,   0.3478,  -0.8923,  47.2151,   0.3844,   1.0316,  -1.0382,\n",
            "        -35.3586,  -1.0089,   0.7150,   0.7882,  -0.3077],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 30\n",
            " Current loss 19.948265075683594\n",
            "\n",
            "tensor([  0.7205,   0.3798,  -0.9955,  49.4271,   0.6743,   1.3447,  -1.0453,\n",
            "        -36.8963,  -0.8853,   0.4131,   0.4314,  -0.4270],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 31\n",
            " Current loss 6.114557266235352\n",
            "\n",
            "tensor([  0.5880,   0.2317,  -1.1222,  52.5125,   0.8428,   1.5345,  -1.0167,\n",
            "        -39.1956,  -0.6815,   0.0854,   0.2132,  -0.4916],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 32\n",
            " Current loss 11.235663414001465\n",
            "\n",
            "tensor([ 4.7005e-01, -4.4477e-02, -1.1505e+00,  5.2951e+01,  8.2870e-01,\n",
            "         1.5128e+00, -8.9050e-01, -3.9583e+01, -3.9642e-01, -2.3872e-01,\n",
            "         1.4115e-01, -4.5793e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 33\n",
            " Current loss 14.030610084533691\n",
            "\n",
            "tensor([  0.3850,  -0.3370,  -1.0564,  50.4423,   0.6635,   1.3185,  -0.6947,\n",
            "        -37.7981,  -0.1061,  -0.4768,   0.1997,  -0.3461],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 34\n",
            " Current loss 3.242805004119873\n",
            "\n",
            "tensor([  0.3698,  -0.6337,  -0.9425,  48.1524,   0.4421,   1.0742,  -0.5211,\n",
            "        -36.2282,   0.1474,  -0.6128,   0.3568,  -0.2254],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 35\n",
            " Current loss 9.960283279418945\n",
            "\n",
            "tensor([  0.4147,  -0.8798,  -0.8501,  48.3120,   0.2336,   0.8861,  -0.3624,\n",
            "        -36.5489,   0.3718,  -0.6795,   0.5651,  -0.1104],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 36\n",
            " Current loss 8.114686965942383\n",
            "\n",
            "tensor([ 5.0342e-01, -1.0488e+00, -7.3438e-01,  5.0443e+01,  5.9486e-02,\n",
            "         7.8135e-01, -2.0804e-01, -3.8377e+01,  5.6644e-01, -6.8807e-01,\n",
            "         7.9219e-01, -2.3243e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 37\n",
            " Current loss 2.5505902767181396\n",
            "\n",
            "tensor([ 5.9996e-01, -1.0554e+00, -5.0156e-01,  5.2034e+01, -3.7083e-02,\n",
            "         7.8114e-01, -6.8284e-02, -3.9738e+01,  6.7546e-01, -6.2210e-01,\n",
            "         9.6204e-01,  8.5583e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 38\n",
            " Current loss 8.34963607788086\n",
            "\n",
            "tensor([ 6.6596e-01, -8.5392e-01, -1.5440e-01,  5.1241e+01, -2.9723e-02,\n",
            "         8.6205e-01,  3.1964e-02, -3.9161e+01,  6.5580e-01, -4.9499e-01,\n",
            "         1.0177e+00,  1.3943e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 39\n",
            " Current loss 3.711130142211914\n",
            "\n",
            "tensor([  0.7174,  -0.5409,   0.2113,  49.2078,   0.0498,   0.9941,   0.0934,\n",
            "        -37.5537,   0.5522,  -0.3314,   0.9922,   0.1610],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 40\n",
            " Current loss 1.9918712377548218\n",
            "\n",
            "tensor([  0.7954,  -0.2288,   0.5144,  48.3206,   0.1506,   1.1395,   0.1426,\n",
            "        -36.8108,   0.4441,  -0.1577,   0.9737,   0.1707],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 41\n",
            " Current loss 5.727174758911133\n",
            "\n",
            "tensor([ 9.2117e-01,  3.7126e-02,  7.3415e-01,  4.9408e+01,  2.4206e-01,\n",
            "         1.2702e+00,  1.9761e-01, -3.7598e+01,  3.6291e-01,  2.3126e-02,\n",
            "         1.0101e+00,  1.8046e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 42\n",
            " Current loss 1.8287701606750488\n",
            "\n",
            "tensor([  1.0723,   0.2284,   0.8478,  51.1871,   0.3007,   1.3345,   0.2511,\n",
            "        -38.9250,   0.2969,   0.2048,   1.0921,   0.1856],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 43\n",
            " Current loss 3.1907966136932373\n",
            "\n",
            "tensor([  1.1920,   0.3017,   0.8238,  51.5785,   0.3031,   1.2761,   0.2804,\n",
            "        -39.1782,   0.2276,   0.3526,   1.1773,   0.1755],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 44\n",
            " Current loss 4.740261554718018\n",
            "\n",
            "tensor([  1.2513,   0.2495,   0.6804,  50.2544,   0.2536,   1.1104,   0.2810,\n",
            "        -38.1019,   0.1588,   0.4355,   1.2388,   0.1512],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 45\n",
            " Current loss 1.2606314420700073\n",
            "\n",
            "tensor([  1.2764,   0.1431,   0.5190,  49.2318,   0.1992,   0.9520,   0.2764,\n",
            "        -37.2666,   0.1181,   0.4571,   1.2822,   0.1305],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 46\n",
            " Current loss 2.493311643600464\n",
            "\n",
            "tensor([ 1.3038e+00,  2.6682e-03,  3.4260e-01,  4.9187e+01,  1.5064e-01,\n",
            "         8.0627e-01,  2.7845e-01, -3.7178e+01,  9.4420e-02,  4.4749e-01,\n",
            "         1.3311e+00,  1.1323e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 47\n",
            " Current loss 2.527153491973877\n",
            "\n",
            "tensor([  1.3333,  -0.1505,   0.1715,  50.1048,   0.1226,   0.6931,   0.2862,\n",
            "        -37.8158,   0.0789,   0.4092,   1.3740,   0.0974],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 48\n",
            " Current loss 0.7297317981719971\n",
            "\n",
            "tensor([ 1.3396e+00, -2.9200e-01,  2.9427e-02,  5.1093e+01,  1.2902e-01,\n",
            "         6.2659e-01,  2.8709e-01, -3.8481e+01,  5.5421e-02,  3.3484e-01,\n",
            "         1.3737e+00,  7.7558e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 49\n",
            " Current loss 1.582301378250122\n",
            "\n",
            "tensor([ 1.2999e+00, -3.9424e-01, -5.8095e-02,  5.1244e+01,  1.7672e-01,\n",
            "         6.1740e-01,  2.6882e-01, -3.8476e+01,  1.2649e-02,  2.2359e-01,\n",
            "         1.3012e+00,  4.9789e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 50\n",
            " Current loss 1.693408489227295\n",
            "\n",
            "tensor([ 1.2217e+00, -4.4565e-01, -8.6945e-02,  5.0534e+01,  2.5721e-01,\n",
            "         6.6217e-01,  2.3203e-01, -3.7800e+01, -4.5300e-02,  9.3039e-02,\n",
            "         1.1698e+00,  1.5746e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 51\n",
            " Current loss 0.3533346652984619\n",
            "\n",
            "tensor([ 1.1368e+00, -4.5939e-01, -7.9555e-02,  4.9794e+01,  3.5263e-01,\n",
            "         7.4484e-01,  1.8875e-01, -3.7112e+01, -1.0361e-01, -3.2746e-02,\n",
            "         1.0247e+00, -2.0147e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 52\n",
            " Current loss 1.0546600818634033\n",
            "\n",
            "tensor([  1.0717,  -0.4565,  -0.0639,  49.7836,   0.4464,   0.8475,   0.1488,\n",
            "        -37.0125,  -0.1499,  -0.1388,   0.9048,  -0.0553],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 53\n",
            " Current loss 1.228315830230713\n",
            "\n",
            "tensor([  1.0307,  -0.4492,  -0.0569,  50.4871,   0.5231,   0.9513,   0.1125,\n",
            "        -37.5001,  -0.1790,  -0.2180,   0.8251,  -0.0887],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 54\n",
            " Current loss 0.42819565534591675\n",
            "\n",
            "tensor([  1.0021,  -0.4402,  -0.0638,  51.1814,   0.5641,   1.0318,   0.0743,\n",
            "        -38.0329,  -0.1897,  -0.2641,   0.7853,  -0.1185],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 55\n",
            " Current loss 1.0857137441635132\n",
            "\n",
            "tensor([ 9.7449e-01, -4.2854e-01, -8.3231e-02,  5.1158e+01,  5.5575e-01,\n",
            "         1.0680e+00,  3.0847e-02, -3.8073e+01, -1.8310e-01, -2.7275e-01,\n",
            "         7.8081e-01, -1.4116e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 56\n",
            " Current loss 1.0613293647766113\n",
            "\n",
            "tensor([ 9.4943e-01, -4.1621e-01, -1.1261e-01,  5.0480e+01,  5.0254e-01,\n",
            "         1.0589e+00, -1.3781e-02, -3.7658e+01, -1.6157e-01, -2.4727e-01,\n",
            "         8.0877e-01, -1.5400e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 57\n",
            " Current loss 0.33436551690101624\n",
            "\n",
            "tensor([  0.9374,  -0.4060,  -0.1500,  49.8558,   0.4234,   1.0237,  -0.0522,\n",
            "        -37.3117,  -0.1279,  -0.1973,   0.8671,  -0.1570],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 58\n",
            " Current loss 0.7141090631484985\n",
            "\n",
            "tensor([  0.9440,  -0.3963,  -0.1899,  49.8503,   0.3373,   0.9843,  -0.0807,\n",
            "        -37.4517,  -0.0861,  -0.1332,   0.9495,  -0.1509],\n",
            "       grad_fn=<AddBackward0>)\n",
            "Epoch number 59\n",
            " Current loss 0.5189619660377502\n",
            "\n",
            "tensor([ 9.6091e-01, -3.7844e-01, -2.1868e-01,  5.0350e+01,  2.5717e-01,\n",
            "         9.5379e-01, -1.0044e-01, -3.7976e+01, -4.2651e-02, -6.4158e-02,\n",
            "         1.0385e+00, -1.3592e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 60\n",
            " Current loss 0.10248465836048126\n",
            "\n",
            "tensor([ 9.6812e-01, -3.4846e-01, -2.1731e-01,  5.0662e+01,  2.0702e-01,\n",
            "         9.4145e-01, -1.1186e-01, -3.8311e+01, -1.4821e-02, -1.3451e-02,\n",
            "         1.0920e+00, -1.1656e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 61\n",
            " Current loss 0.38939082622528076\n",
            "\n",
            "tensor([ 9.6070e-01, -3.0090e-01, -1.8509e-01,  5.0596e+01,  1.7596e-01,\n",
            "         9.4263e-01, -1.2021e-01, -3.8327e+01,  1.2972e-03,  2.6220e-02,\n",
            "         1.1144e+00, -9.0605e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 62\n",
            " Current loss 0.34804999828338623\n",
            "\n",
            "tensor([ 9.3989e-01, -2.4198e-01, -1.2715e-01,  5.0216e+01,  1.6461e-01,\n",
            "         9.5664e-01, -1.2508e-01, -3.8071e+01,  6.1693e-03,  5.2005e-02,\n",
            "         1.1065e+00, -5.9855e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 63\n",
            " Current loss 0.0984354317188263\n",
            "\n",
            "tensor([ 9.1434e-01, -1.8262e-01, -5.6813e-02,  4.9857e+01,  1.6900e-01,\n",
            "         9.8090e-01, -1.2506e-01, -3.7807e+01,  4.8122e-03,  6.5320e-02,\n",
            "         1.0809e+00, -2.6213e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 64\n",
            " Current loss 0.2591729164123535\n",
            "\n",
            "tensor([ 8.9251e-01, -1.3302e-01,  1.2580e-02,  4.9812e+01,  1.8296e-01,\n",
            "         1.0107e+00, -1.1908e-01, -3.7769e+01,  2.8338e-03,  6.9364e-02,\n",
            "         1.0514e+00,  8.8758e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 65\n",
            " Current loss 0.31409725546836853\n",
            "\n",
            "tensor([ 8.7726e-01, -1.0039e-01,  7.1991e-02,  5.0093e+01,  2.0023e-01,\n",
            "         1.0388e+00, -1.0743e-01, -3.7971e+01,  3.3062e-03,  6.6570e-02,\n",
            "         1.0252e+00,  4.3866e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 66\n",
            " Current loss 0.12067491561174393\n",
            "\n",
            "tensor([ 8.6616e-01, -8.9119e-02,  1.1606e-01,  5.0436e+01,  2.1529e-01,\n",
            "         1.0559e+00, -9.1886e-02, -3.8215e+01,  6.3779e-03,  5.8112e-02,\n",
            "         1.0022e+00,  7.6267e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 67\n",
            " Current loss 0.20310035347938538\n",
            "\n",
            "tensor([ 8.5604e-01, -1.0067e-01,  1.4141e-01,  5.0546e+01,  2.2407e-01,\n",
            "         1.0547e+00, -7.4929e-02, -3.8274e+01,  1.0939e-02,  4.5200e-02,\n",
            "         9.8092e-01,  1.0284e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 68\n",
            " Current loss 0.2891538441181183\n",
            "\n",
            "tensor([ 8.4734e-01, -1.3283e-01,  1.4638e-01,  5.0353e+01,  2.2517e-01,\n",
            "         1.0344e+00, -5.8262e-02, -3.8100e+01,  1.6647e-02,  3.0296e-02,\n",
            "         9.6259e-01,  1.2109e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 69\n",
            " Current loss 0.12450850754976273\n",
            "\n",
            "tensor([ 8.4442e-01, -1.8032e-01,  1.3167e-01,  5.0068e+01,  2.2036e-01,\n",
            "         1.0015e+00, -4.2034e-02, -3.7855e+01,  2.4389e-02,  1.6701e-02,\n",
            "         9.5177e-01,  1.3042e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 70\n",
            " Current loss 0.12290114164352417\n",
            "\n",
            "tensor([ 8.5166e-01, -2.3630e-01,  1.0069e-01,  4.9961e+01,  2.1339e-01,\n",
            "         9.6522e-01, -2.5660e-02, -3.7752e+01,  3.4826e-02,  6.9487e-03,\n",
            "         9.5193e-01,  1.3150e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 71\n",
            " Current loss 0.18736359477043152\n",
            "\n",
            "tensor([ 8.6940e-01, -2.9291e-01,  5.9618e-02,  5.0120e+01,  2.0857e-01,\n",
            "         9.3339e-01, -9.3531e-03, -3.7856e+01,  4.6618e-02,  1.7659e-03,\n",
            "         9.6128e-01,  1.2491e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 72\n",
            " Current loss 0.07167080789804459\n",
            "\n",
            "tensor([ 8.9297e-01, -3.4116e-01,  1.7012e-02,  5.0390e+01,  2.0984e-01,\n",
            "         9.1078e-01,  5.2120e-03, -3.8044e+01,  5.6089e-02,  2.1356e-04,\n",
            "         9.7253e-01,  1.1067e-01], grad_fn=<AddBackward0>)\n",
            "Epoch number 73\n",
            " Current loss 0.059909529983997345\n",
            "\n",
            "tensor([ 9.1572e-01, -3.7258e-01, -1.8170e-02,  5.0525e+01,  2.1981e-01,\n",
            "         8.9989e-01,  1.5816e-02, -3.8124e+01,  5.9077e-02,  5.9139e-04,\n",
            "         9.7715e-01,  8.9151e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 74\n",
            " Current loss 0.1301809400320053\n",
            "\n",
            "tensor([ 9.3374e-01, -3.8297e-01, -4.0352e-02,  5.0423e+01,  2.3886e-01,\n",
            "         9.0156e-01,  2.1530e-02, -3.8018e+01,  5.3846e-02,  1.6557e-03,\n",
            "         9.7158e-01,  6.2004e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 75\n",
            " Current loss 0.055035486817359924\n",
            "\n",
            "tensor([ 9.4533e-01, -3.7620e-01, -4.7827e-02,  5.0254e+01,  2.5973e-01,\n",
            "         9.1229e-01,  2.3166e-02, -3.7863e+01,  4.4577e-02,  2.9199e-03,\n",
            "         9.6201e-01,  3.8013e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 76\n",
            " Current loss 0.02454228326678276\n",
            "\n",
            "tensor([ 9.5655e-01, -3.5872e-01, -4.7854e-02,  5.0137e+01,  2.8379e-01,\n",
            "         9.3048e-01,  2.3355e-02, -3.7750e+01,  3.2692e-02,  4.8307e-03,\n",
            "         9.5221e-01,  1.3616e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 77\n",
            " Current loss 0.0647055134177208\n",
            "\n",
            "tensor([ 9.6910e-01, -3.3544e-01, -4.3712e-02,  5.0162e+01,  3.0807e-01,\n",
            "         9.5296e-01,  2.3288e-02, -3.7748e+01,  2.0403e-02,  7.4468e-03,\n",
            "         9.4640e-01, -9.6614e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 78\n",
            " Current loss 0.05379645526409149\n",
            "\n",
            "tensor([ 9.8243e-01, -3.1050e-01, -3.7739e-02,  5.0305e+01,  3.2937e-01,\n",
            "         9.7537e-01,  2.3285e-02, -3.7841e+01,  8.9049e-03,  1.0375e-02,\n",
            "         9.4624e-01, -3.0654e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 79\n",
            " Current loss 0.014661433175206184\n",
            "\n",
            "tensor([ 9.9414e-01, -2.8706e-01, -3.1138e-02,  5.0453e+01,  3.4462e-01,\n",
            "         9.9290e-01,  2.2946e-02, -3.7944e+01, -1.4871e-03,  1.2826e-02,\n",
            "         9.5112e-01, -4.8341e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 80\n",
            " Current loss 0.038411255925893784\n",
            "\n",
            "tensor([ 1.0018e+00, -2.6769e-01, -2.4667e-02,  5.0497e+01,  3.5156e-01,\n",
            "         1.0017e+00,  2.1817e-02, -3.7972e+01, -1.0641e-02,  1.4035e-02,\n",
            "         9.5964e-01, -6.1818e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 81\n",
            " Current loss 0.059180162847042084\n",
            "\n",
            "tensor([ 1.0049e+00, -2.5440e-01, -1.9223e-02,  5.0413e+01,  3.4949e-01,\n",
            "         1.0005e+00,  1.9979e-02, -3.7908e+01, -1.8059e-02,  1.3679e-02,\n",
            "         9.7120e-01, -7.0454e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 82\n",
            " Current loss 0.02917342260479927\n",
            "\n",
            "tensor([ 1.0050e+00, -2.4833e-01, -1.5786e-02,  5.0278e+01,  3.3952e-01,\n",
            "         9.9068e-01,  1.8121e-02, -3.7810e+01, -2.2940e-02,  1.1984e-02,\n",
            "         9.8626e-01, -7.4068e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 83\n",
            " Current loss 0.023836690932512283\n",
            "\n",
            "tensor([ 1.0045e+00, -2.4933e-01, -1.4746e-02,  5.0199e+01,  3.2399e-01,\n",
            "         9.7553e-01,  1.7025e-02, -3.7759e+01, -2.4733e-02,  9.3809e-03,\n",
            "         1.0052e+00, -7.2911e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 84\n",
            " Current loss 0.04273737967014313\n",
            "\n",
            "tensor([ 1.0044e+00, -2.5584e-01, -1.5290e-02,  5.0228e+01,  3.0568e-01,\n",
            "         9.5855e-01,  1.6960e-02, -3.7795e+01, -2.3685e-02,  6.1100e-03,\n",
            "         1.0267e+00, -6.7530e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 85\n",
            " Current loss 0.0264247078448534\n",
            "\n",
            "tensor([ 1.0040e+00, -2.6511e-01, -1.5423e-02,  5.0330e+01,  2.8731e-01,\n",
            "         9.4259e-01,  1.7457e-02, -3.7887e+01, -2.0936e-02,  2.0939e-03,\n",
            "         1.0474e+00, -5.8661e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 86\n",
            " Current loss 0.01024935394525528\n",
            "\n",
            "tensor([ 1.0014e+00, -2.7400e-01, -1.2794e-02,  5.0412e+01,  2.7132e-01,\n",
            "         9.2980e-01,  1.7644e-02, -3.7964e+01, -1.8051e-02, -2.8431e-03,\n",
            "         1.0630e+00, -4.7197e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 87\n",
            " Current loss 0.025821557268500328\n",
            "\n",
            "tensor([ 9.9555e-01, -2.7997e-01, -5.9500e-03,  5.0408e+01,  2.5958e-01,\n",
            "         9.2178e-01,  1.6843e-02, -3.7970e+01, -1.6217e-02, -8.6031e-03,\n",
            "         1.0701e+00, -3.4176e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 88\n",
            " Current loss 0.025770755484700203\n",
            "\n",
            "tensor([ 9.8705e-01, -2.8197e-01,  4.7789e-03,  5.0325e+01,  2.5310e-01,\n",
            "         9.1963e-01,  1.5019e-02, -3.7912e+01, -1.5648e-02, -1.4579e-02,\n",
            "         1.0685e+00, -2.0636e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 89\n",
            " Current loss 0.009441395290195942\n",
            "\n",
            "tensor([ 9.7808e-01, -2.8048e-01,  1.7502e-02,  5.0234e+01,  2.5191e-01,\n",
            "         9.2368e-01,  1.2698e-02, -3.7845e+01, -1.5657e-02, -1.9815e-02,\n",
            "         1.0605e+00, -7.4551e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 90\n",
            " Current loss 0.014869162812829018\n",
            "\n",
            "tensor([ 9.7227e-01, -2.7755e-01,  2.7304e-02,  5.0214e+01,  2.5445e-01,\n",
            "         9.3128e-01,  1.0922e-02, -3.7830e+01, -1.5359e-02, -2.2692e-02,\n",
            "         1.0515e+00,  2.2517e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 91\n",
            " Current loss 0.01855289191007614\n",
            "\n",
            "tensor([ 9.6837e-01, -2.7382e-01,  3.5434e-02,  5.0254e+01,  2.5944e-01,\n",
            "         9.4193e-01,  9.3627e-03, -3.7861e+01, -1.4383e-02, -2.3944e-02,\n",
            "         1.0415e+00,  1.0787e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 92\n",
            " Current loss 0.00862925499677658\n",
            "\n",
            "tensor([ 9.6599e-01, -2.7005e-01,  4.1024e-02,  5.0322e+01,  2.6561e-01,\n",
            "         9.5376e-01,  7.8842e-03, -3.7914e+01, -1.2681e-02, -2.3519e-02,\n",
            "         1.0310e+00,  1.7841e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 93\n",
            " Current loss 0.0045286426320672035\n",
            "\n",
            "tensor([ 9.6432e-01, -2.6685e-01,  4.3590e-02,  5.0371e+01,  2.7169e-01,\n",
            "         9.6476e-01,  6.2504e-03, -3.7952e+01, -1.0403e-02, -2.1561e-02,\n",
            "         1.0203e+00,  2.3164e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 94\n",
            " Current loss 0.010998700745403767\n",
            "\n",
            "tensor([ 9.6276e-01, -2.6476e-01,  4.2858e-02,  5.0370e+01,  2.7661e-01,\n",
            "         9.7332e-01,  4.3392e-03, -3.7953e+01, -7.6787e-03, -1.8313e-02,\n",
            "         1.0097e+00,  2.6627e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 95\n",
            " Current loss 0.01068730279803276\n",
            "\n",
            "tensor([ 9.6134e-01, -2.6427e-01,  3.8704e-02,  5.0324e+01,  2.7970e-01,\n",
            "         9.7861e-01,  2.2737e-03, -3.7920e+01, -4.4782e-03, -1.4022e-02,\n",
            "         1.0001e+00,  2.8271e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 96\n",
            " Current loss 0.003783575724810362\n",
            "\n",
            "tensor([ 9.6057e-01, -2.6566e-01,  3.1208e-02,  5.0266e+01,  2.8077e-01,\n",
            "         9.8067e-01,  3.6135e-04, -3.7879e+01, -6.6419e-04, -8.9222e-03,\n",
            "         9.9272e-01,  2.8287e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 97\n",
            " Current loss 0.0041875396855175495\n",
            "\n",
            "tensor([ 9.6096e-01, -2.6890e-01,  2.0858e-02,  5.0236e+01,  2.8003e-01,\n",
            "         9.8010e-01, -1.0939e-03, -3.7860e+01,  3.7961e-03, -3.3123e-03,\n",
            "         9.8834e-01,  2.6956e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 98\n",
            " Current loss 0.007798955775797367\n",
            "\n",
            "tensor([ 9.6249e-01, -2.7347e-01,  8.6658e-03,  5.0249e+01,  2.7798e-01,\n",
            "         9.7768e-01, -1.9833e-03, -3.7876e+01,  8.6517e-03,  2.3840e-03,\n",
            "         9.8691e-01,  2.4552e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 99\n",
            " Current loss 0.004581598564982414\n",
            "\n",
            "tensor([ 9.6446e-01, -2.7846e-01, -3.8710e-03,  5.0292e+01,  2.7524e-01,\n",
            "         9.7416e-01, -2.4471e-03, -3.7914e+01,  1.3323e-02,  7.6293e-03,\n",
            "         9.8747e-01,  2.1315e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 100\n",
            " Current loss 0.0012101333122700453\n",
            "\n",
            "tensor([ 9.6586e-01, -2.8279e-01, -1.5084e-02,  5.0332e+01,  2.7247e-01,\n",
            "         9.7017e-01, -2.7667e-03, -3.7948e+01,  1.7079e-02,  1.1840e-02,\n",
            "         9.8856e-01,  1.7462e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 101\n",
            " Current loss 0.004186100792139769\n",
            "\n",
            "tensor([ 9.6584e-01, -2.8555e-01, -2.3563e-02,  5.0339e+01,  2.7026e-01,\n",
            "         9.6630e-01, -3.1924e-03, -3.7956e+01,  1.9322e-02,  1.4589e-02,\n",
            "         9.8892e-01,  1.3223e-02], grad_fn=<AddBackward0>)\n",
            "Epoch number 102\n",
            " Current loss 0.005887479521334171\n",
            "\n",
            "tensor([ 9.6423e-01, -2.8632e-01, -2.8548e-02,  5.0313e+01,  2.6904e-01,\n",
            "         9.6316e-01, -3.7891e-03, -3.7936e+01,  1.9827e-02,  1.5697e-02,\n",
            "         9.8805e-01,  8.8517e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 103\n",
            " Current loss 0.0030394671484827995\n",
            "\n",
            "tensor([ 9.6151e-01, -2.8518e-01, -3.0033e-02,  5.0273e+01,  2.6904e-01,\n",
            "         9.6128e-01, -4.4373e-03, -3.7904e+01,  1.8776e-02,  1.5285e-02,\n",
            "         9.8626e-01,  4.6147e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 104\n",
            " Current loss 0.002590162679553032\n",
            "\n",
            "tensor([ 9.5844e-01, -2.8263e-01, -2.8553e-02,  5.0250e+01,  2.7019e-01,\n",
            "         9.6089e-01, -4.9511e-03, -3.7883e+01,  1.6585e-02,  1.3651e-02,\n",
            "         9.8431e-01,  7.3795e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 105\n",
            " Current loss 0.004619099665433168\n",
            "\n",
            "tensor([ 9.5617e-01, -2.7995e-01, -2.5591e-02,  5.0257e+01,  2.7181e-01,\n",
            "         9.6164e-01, -5.1692e-03, -3.7885e+01,  1.4253e-02,  1.1653e-02,\n",
            "         9.8313e-01, -1.9430e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 106\n",
            " Current loss 0.003612094558775425\n",
            "\n",
            "tensor([ 9.5417e-01, -2.7702e-01, -2.1345e-02,  5.0284e+01,  2.7381e-01,\n",
            "         9.6306e-01, -5.2298e-03, -3.7902e+01,  1.1531e-02,  9.1784e-03,\n",
            "         9.8249e-01, -4.1660e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 107\n",
            " Current loss 0.001354510779492557\n",
            "\n",
            "tensor([ 9.5232e-01, -2.7414e-01, -1.6255e-02,  5.0315e+01,  2.7582e-01,\n",
            "         9.6460e-01, -5.2360e-03, -3.7923e+01,  8.5352e-03,  6.4050e-03,\n",
            "         9.8231e-01, -5.9148e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 108\n",
            " Current loss 0.001410908647812903\n",
            "\n",
            "tensor([ 9.5048e-01, -2.7162e-01, -1.0770e-02,  5.0333e+01,  2.7749e-01,\n",
            "         9.6571e-01, -5.2987e-03, -3.7933e+01,  5.3710e-03,  3.5218e-03,\n",
            "         9.8247e-01, -7.2059e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 109\n",
            " Current loss 0.0025961685460060835\n",
            "\n",
            "tensor([ 9.4866e-01, -2.6971e-01, -5.3717e-03,  5.0329e+01,  2.7855e-01,\n",
            "         9.6603e-01, -5.4602e-03, -3.7927e+01,  2.2049e-03,  7.3264e-04,\n",
            "         9.8301e-01, -8.0590e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 110\n",
            " Current loss 0.0020342469215393066\n",
            "\n",
            "tensor([ 9.4710e-01, -2.6867e-01, -5.7725e-04,  5.0309e+01,  2.7885e-01,\n",
            "         9.6541e-01, -5.6747e-03, -3.7909e+01, -7.3496e-04, -1.7393e-03,\n",
            "         9.8412e-01, -8.5035e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 111\n",
            " Current loss 0.0007507103146053851\n",
            "\n",
            "tensor([ 9.4617e-01, -2.6865e-01,  3.1744e-03,  5.0286e+01,  2.7838e-01,\n",
            "         9.6397e-01, -5.8402e-03, -3.7890e+01, -3.1996e-03, -3.6899e-03,\n",
            "         9.8610e-01, -8.5653e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 112\n",
            " Current loss 0.0010051728459075093\n",
            "\n",
            "tensor([ 9.4617e-01, -2.6965e-01,  5.6152e-03,  5.0274e+01,  2.7725e-01,\n",
            "         9.6196e-01, -5.8515e-03, -3.7880e+01, -5.0145e-03, -4.9736e-03,\n",
            "         9.8911e-01, -8.2831e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 113\n",
            " Current loss 0.0017944870050996542\n",
            "\n",
            "tensor([ 9.4718e-01, -2.7150e-01,  6.7256e-03,  5.0279e+01,  2.7568e-01,\n",
            "         9.5967e-01, -5.6650e-03, -3.7885e+01, -6.1352e-03, -5.5551e-03,\n",
            "         9.9306e-01, -7.7086e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 114\n",
            " Current loss 0.0012816507369279861\n",
            "\n",
            "tensor([ 9.4902e-01, -2.7386e-01,  6.7336e-03,  5.0297e+01,  2.7392e-01,\n",
            "         9.5739e-01, -5.3138e-03, -3.7899e+01, -6.6657e-03, -5.4978e-03,\n",
            "         9.9752e-01, -6.9100e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 115\n",
            " Current loss 0.0004077746416442096\n",
            "\n",
            "tensor([ 9.5131e-01, -2.7627e-01,  6.0354e-03,  5.0315e+01,  2.7222e-01,\n",
            "         9.5533e-01, -4.8882e-03, -3.7914e+01, -6.8052e-03, -4.9434e-03,\n",
            "         1.0019e+00, -5.9567e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 116\n",
            " Current loss 0.0006602799985557795\n",
            "\n",
            "tensor([ 9.5367e-01, -2.7832e-01,  5.0474e-03,  5.0323e+01,  2.7085e-01,\n",
            "         9.5372e-01, -4.4692e-03, -3.7922e+01, -6.7627e-03, -4.0607e-03,\n",
            "         1.0055e+00, -4.9202e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 117\n",
            " Current loss 0.0011824542889371514\n",
            "\n",
            "tensor([ 9.5586e-01, -2.7971e-01,  4.0931e-03,  5.0317e+01,  2.7000e-01,\n",
            "         9.5274e-01, -4.0921e-03, -3.7918e+01, -6.6742e-03, -3.0019e-03,\n",
            "         1.0081e+00, -3.8548e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 118\n",
            " Current loss 0.0008105358574539423\n",
            "\n",
            "tensor([ 9.5783e-01, -2.8031e-01,  3.3367e-03,  5.0301e+01,  2.6980e-01,\n",
            "         9.5257e-01, -3.7221e-03, -3.7906e+01, -6.5806e-03, -1.8787e-03,\n",
            "         1.0096e+00, -2.7965e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 119\n",
            " Current loss 0.00032280696905218065\n",
            "\n",
            "tensor([ 9.5969e-01, -2.8016e-01,  2.8000e-03,  5.0286e+01,  2.7030e-01,\n",
            "         9.5332e-01, -3.2874e-03, -3.7895e+01, -6.4400e-03, -7.6107e-04,\n",
            "         1.0102e+00, -1.7647e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 120\n",
            " Current loss 0.0005721834022551775\n",
            "\n",
            "tensor([ 9.6116e-01, -2.7955e-01,  2.5055e-03,  5.0281e+01,  2.7120e-01,\n",
            "         9.5462e-01, -2.8378e-03, -3.7891e+01, -6.2411e-03,  7.9408e-05,\n",
            "         1.0101e+00, -9.7125e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 121\n",
            " Current loss 0.0007559685036540031\n",
            "\n",
            "tensor([ 9.6261e-01, -2.7858e-01,  2.3081e-03,  5.0286e+01,  2.7251e-01,\n",
            "         9.5649e-01, -2.2750e-03, -3.7894e+01, -5.9372e-03,  8.3784e-04,\n",
            "         1.0096e+00, -2.2250e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 122\n",
            " Current loss 0.0004744422622025013\n",
            "\n",
            "tensor([ 9.6396e-01, -2.7737e-01,  2.1793e-03,  5.0297e+01,  2.7406e-01,\n",
            "         9.5870e-01, -1.6216e-03, -3.7902e+01, -5.5406e-03,  1.4608e-03,\n",
            "         1.0087e+00,  4.6746e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 123\n",
            " Current loss 0.00015017457189969718\n",
            "\n",
            "tensor([ 9.6508e-01, -2.7605e-01,  2.0979e-03,  5.0308e+01,  2.7569e-01,\n",
            "         9.6098e-01, -9.2824e-04, -3.7910e+01, -5.0767e-03,  1.9135e-03,\n",
            "         1.0076e+00,  1.0888e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 124\n",
            " Current loss 0.0002110509085468948\n",
            "\n",
            "tensor([ 9.6587e-01, -2.7477e-01,  2.0383e-03,  5.0315e+01,  2.7723e-01,\n",
            "         9.6308e-01, -2.4112e-04, -3.7914e+01, -4.5736e-03,  2.1701e-03,\n",
            "         1.0062e+00,  1.6242e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 125\n",
            " Current loss 0.0004092225572094321\n",
            "\n",
            "tensor([ 9.6629e-01, -2.7363e-01,  1.9417e-03,  5.0313e+01,  2.7854e-01,\n",
            "         9.6479e-01,  4.1279e-04, -3.7912e+01, -4.0290e-03,  2.2320e-03,\n",
            "         1.0046e+00,  2.0642e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 126\n",
            " Current loss 0.0003480702289380133\n",
            "\n",
            "tensor([ 9.6639e-01, -2.7278e-01,  1.7435e-03,  5.0306e+01,  2.7950e-01,\n",
            "         9.6598e-01,  1.0277e-03, -3.7906e+01, -3.4262e-03,  2.1156e-03,\n",
            "         1.0030e+00,  2.4110e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 127\n",
            " Current loss 0.00014808452397119254\n",
            "\n",
            "tensor([ 9.6629e-01, -2.7233e-01,  1.3629e-03,  5.0297e+01,  2.8007e-01,\n",
            "         9.6662e-01,  1.6152e-03, -3.7899e+01, -2.7270e-03,  1.8727e-03,\n",
            "         1.0016e+00,  2.6675e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 128\n",
            " Current loss 0.0001467908441554755\n",
            "\n",
            "tensor([ 9.6611e-01, -2.7232e-01,  7.6529e-04,  5.0291e+01,  2.8022e-01,\n",
            "         9.6674e-01,  2.1879e-03, -3.7894e+01, -1.9105e-03,  1.5502e-03,\n",
            "         1.0006e+00,  2.8351e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 129\n",
            " Current loss 0.0002937359386123717\n",
            "\n",
            "tensor([ 9.6593e-01, -2.7274e-01, -3.8754e-05,  5.0291e+01,  2.8001e-01,\n",
            "         9.6640e-01,  2.7472e-03, -3.7893e+01, -9.8300e-04,  1.1804e-03,\n",
            "         9.9999e-01,  2.9243e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 130\n",
            " Current loss 0.000294964003842324\n",
            "\n",
            "tensor([ 9.6576e-01, -2.7352e-01, -9.7388e-04,  5.0296e+01,  2.7949e-01,\n",
            "         9.6570e-01,  3.2708e-03, -3.7897e+01,  1.1697e-05,  7.9200e-04,\n",
            "         9.9979e-01,  2.9277e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 131\n",
            " Current loss 0.0001411140983691439\n",
            "\n",
            "tensor([ 9.6556e-01, -2.7451e-01, -1.9141e-03,  5.0303e+01,  2.7876e-01,\n",
            "         9.6473e-01,  3.7135e-03, -3.7903e+01,  9.9485e-04,  3.9072e-04,\n",
            "         9.9986e-01,  2.8461e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 132\n",
            " Current loss 7.732342783128843e-05\n",
            "\n",
            "tensor([ 9.6525e-01, -2.7556e-01, -2.7193e-03,  5.0309e+01,  2.7790e-01,\n",
            "         9.6359e-01,  4.0337e-03, -3.7908e+01,  1.8811e-03, -2.0564e-05,\n",
            "         1.0000e+00,  2.6801e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 133\n",
            " Current loss 0.00015663339581806213\n",
            "\n",
            "tensor([ 9.6479e-01, -2.7653e-01, -3.2742e-03,  5.0310e+01,  2.7703e-01,\n",
            "         9.6241e-01,  4.1990e-03, -3.7910e+01,  2.5989e-03, -4.3993e-04,\n",
            "         1.0002e+00,  2.4306e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 134\n",
            " Current loss 0.00019057323515880853\n",
            "\n",
            "tensor([ 9.6418e-01, -2.7731e-01, -3.5095e-03,  5.0306e+01,  2.7625e-01,\n",
            "         9.6129e-01,  4.1983e-03, -3.7907e+01,  3.1100e-03, -8.4590e-04,\n",
            "         1.0002e+00,  2.1065e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 135\n",
            " Current loss 0.00010914360609604046\n",
            "\n",
            "tensor([ 9.6363e-01, -2.7773e-01, -3.4330e-03,  5.0302e+01,  2.7574e-01,\n",
            "         9.6056e-01,  4.0831e-03, -3.7904e+01,  3.3544e-03, -1.1440e-03,\n",
            "         1.0001e+00,  1.7976e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 136\n",
            " Current loss 5.6699813285376877e-05\n",
            "\n",
            "tensor([ 9.6308e-01, -2.7794e-01, -3.1249e-03,  5.0297e+01,  2.7539e-01,\n",
            "         9.6002e-01,  3.8669e-03, -3.7900e+01,  3.4499e-03, -1.3916e-03,\n",
            "         9.9991e-01,  1.4546e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 137\n",
            " Current loss 7.503934466512874e-05\n",
            "\n",
            "tensor([ 9.6257e-01, -2.7795e-01, -2.6314e-03,  5.0294e+01,  2.7519e-01,\n",
            "         9.5973e-01,  3.5808e-03, -3.7898e+01,  3.4252e-03, -1.5699e-03,\n",
            "         9.9974e-01,  1.0863e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 138\n",
            " Current loss 0.00011416101915528998\n",
            "\n",
            "tensor([ 9.6215e-01, -2.7780e-01, -1.9958e-03,  5.0294e+01,  2.7515e-01,\n",
            "         9.5966e-01,  3.2406e-03, -3.7899e+01,  3.2992e-03, -1.6748e-03,\n",
            "         9.9956e-01,  7.1248e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 139\n",
            " Current loss 0.00010136554192285985\n",
            "\n",
            "tensor([ 9.6182e-01, -2.7750e-01, -1.2717e-03,  5.0297e+01,  2.7523e-01,\n",
            "         9.5979e-01,  2.8619e-03, -3.7901e+01,  3.0940e-03, -1.7034e-03,\n",
            "         9.9941e-01,  3.3990e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 140\n",
            " Current loss 4.859653563471511e-05\n",
            "\n",
            "tensor([ 9.6155e-01, -2.7710e-01, -5.0345e-04,  5.0301e+01,  2.7540e-01,\n",
            "         9.6006e-01,  2.4462e-03, -3.7904e+01,  2.8191e-03, -1.6570e-03,\n",
            "         9.9927e-01, -2.3097e-05], grad_fn=<AddBackward0>)\n",
            "Epoch number 141\n",
            " Current loss 2.173210305045359e-05\n",
            "\n",
            "tensor([ 9.6133e-01, -2.7663e-01,  2.6952e-04,  5.0304e+01,  2.7562e-01,\n",
            "         9.6040e-01,  2.0020e-03, -3.7907e+01,  2.4855e-03, -1.5481e-03,\n",
            "         9.9912e-01, -3.6601e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 142\n",
            " Current loss 3.962452319683507e-05\n",
            "\n",
            "tensor([ 9.6112e-01, -2.7612e-01,  1.0026e-03,  5.0306e+01,  2.7584e-01,\n",
            "         9.6075e-01,  1.5317e-03, -3.7908e+01,  2.1104e-03, -1.3854e-03,\n",
            "         9.9897e-01, -6.7833e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 143\n",
            " Current loss 5.7266650401288643e-05\n",
            "\n",
            "tensor([ 9.6093e-01, -2.7564e-01,  1.6484e-03,  5.0305e+01,  2.7603e-01,\n",
            "         9.6104e-01,  1.0509e-03, -3.7907e+01,  1.7114e-03, -1.1787e-03,\n",
            "         9.9883e-01, -9.5647e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 144\n",
            " Current loss 4.149171581957489e-05\n",
            "\n",
            "tensor([ 9.6076e-01, -2.7521e-01,  2.1643e-03,  5.0302e+01,  2.7615e-01,\n",
            "         9.6126e-01,  5.7974e-04, -3.7905e+01,  1.3148e-03, -9.3671e-04,\n",
            "         9.9872e-01, -1.1888e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 145\n",
            " Current loss 1.5944649931043386e-05\n",
            "\n",
            "tensor([ 9.6064e-01, -2.7487e-01,  2.5135e-03,  5.0299e+01,  2.7621e-01,\n",
            "         9.6139e-01,  1.3626e-04, -3.7903e+01,  9.5105e-04, -6.5992e-04,\n",
            "         9.9870e-01, -1.3711e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 146\n",
            " Current loss 1.5981415344867855e-05\n",
            "\n",
            "tensor([ 9.6059e-01, -2.7466e-01,  2.6706e-03,  5.0296e+01,  2.7617e-01,\n",
            "         9.6142e-01, -2.5664e-04, -3.7901e+01,  6.3836e-04, -3.6310e-04,\n",
            "         9.9878e-01, -1.4961e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 147\n",
            " Current loss 3.457039565546438e-05\n",
            "\n",
            "tensor([ 9.6062e-01, -2.7458e-01,  2.6359e-03,  5.0296e+01,  2.7606e-01,\n",
            "         9.6137e-01, -5.8751e-04, -3.7901e+01,  3.9291e-04, -5.6766e-05,\n",
            "         9.9899e-01, -1.5615e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 148\n",
            " Current loss 3.904963523382321e-05\n",
            "\n",
            "tensor([ 9.6072e-01, -2.7462e-01,  2.4309e-03,  5.0297e+01,  2.7588e-01,\n",
            "         9.6126e-01, -8.4965e-04, -3.7902e+01,  2.1091e-04,  2.4670e-04,\n",
            "         9.9928e-01, -1.5676e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 149\n",
            " Current loss 2.2542468286701478e-05\n",
            "\n",
            "tensor([ 9.6085e-01, -2.7475e-01,  2.0971e-03,  5.0300e+01,  2.7566e-01,\n",
            "         9.6110e-01, -1.0495e-03, -3.7904e+01,  8.0906e-05,  5.2772e-04,\n",
            "         9.9964e-01, -1.5222e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 150\n",
            " Current loss 9.579848665453028e-06\n",
            "\n",
            "tensor([ 9.6097e-01, -2.7490e-01,  1.7628e-03,  5.0301e+01,  2.7546e-01,\n",
            "         9.6094e-01, -1.1653e-03, -3.7906e+01,  3.9116e-06,  7.2189e-04,\n",
            "         9.9992e-01, -1.4462e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 151\n",
            " Current loss 1.2406536370690446e-05\n",
            "\n",
            "tensor([ 9.6106e-01, -2.7507e-01,  1.4015e-03,  5.0302e+01,  2.7526e-01,\n",
            "         9.6078e-01, -1.2427e-03, -3.7907e+01, -5.7325e-05,  8.7170e-04,\n",
            "         1.0002e+00, -1.3387e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 152\n",
            " Current loss 1.9225262803956866e-05\n",
            "\n",
            "tensor([ 9.6112e-01, -2.7523e-01,  1.0361e-03,  5.0302e+01,  2.7508e-01,\n",
            "         9.6062e-01, -1.2886e-03, -3.7907e+01, -1.1425e-04,  9.7571e-04,\n",
            "         1.0004e+00, -1.2047e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 153\n",
            " Current loss 1.927472294482868e-05\n",
            "\n",
            "tensor([ 9.6115e-01, -2.7539e-01,  6.9341e-04,  5.0301e+01,  2.7493e-01,\n",
            "         9.6048e-01, -1.3085e-03, -3.7906e+01, -1.7019e-04,  1.0339e-03,\n",
            "         1.0005e+00, -1.0501e-03], grad_fn=<AddBackward0>)\n",
            "Epoch number 154\n",
            " Current loss 1.2230462743900716e-05\n",
            "\n",
            "tensor([ 9.6115e-01, -2.7551e-01,  3.8647e-04,  5.0300e+01,  2.7481e-01,\n",
            "         9.6039e-01, -1.2999e-03, -3.7905e+01, -2.2851e-04,  1.0434e-03,\n",
            "         1.0006e+00, -8.7766e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 155\n",
            " Current loss 6.509657396236435e-06\n",
            "\n",
            "tensor([ 9.6113e-01, -2.7561e-01,  1.2174e-04,  5.0299e+01,  2.7474e-01,\n",
            "         9.6035e-01, -1.2668e-03, -3.7904e+01, -2.8537e-04,  1.0119e-03,\n",
            "         1.0006e+00, -6.9853e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 156\n",
            " Current loss 7.665727025596425e-06\n",
            "\n",
            "tensor([ 9.6111e-01, -2.7567e-01, -9.5986e-05,  5.0298e+01,  2.7472e-01,\n",
            "         9.6037e-01, -1.2069e-03, -3.7903e+01, -3.4031e-04,  9.4131e-04,\n",
            "         1.0005e+00, -5.1128e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 157\n",
            " Current loss 1.1704566531989258e-05\n",
            "\n",
            "tensor([ 9.6108e-01, -2.7570e-01, -2.6838e-04,  5.0298e+01,  2.7475e-01,\n",
            "         9.6045e-01, -1.1265e-03, -3.7903e+01, -3.8856e-04,  8.4730e-04,\n",
            "         1.0005e+00, -3.2691e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 158\n",
            " Current loss 1.1817438462458085e-05\n",
            "\n",
            "tensor([ 9.6106e-01, -2.7570e-01, -3.9425e-04,  5.0298e+01,  2.7483e-01,\n",
            "         9.6059e-01, -1.0263e-03, -3.7903e+01, -4.3058e-04,  7.2801e-04,\n",
            "         1.0004e+00, -1.4589e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 159\n",
            " Current loss 7.085255219863029e-06\n",
            "\n",
            "tensor([ 9.6104e-01, -2.7569e-01, -4.7836e-04,  5.0300e+01,  2.7494e-01,\n",
            "         9.6077e-01, -9.1505e-04, -3.7904e+01, -4.6831e-04,  5.9536e-04,\n",
            "         1.0003e+00,  2.3659e-05], grad_fn=<AddBackward0>)\n",
            "Epoch number 160\n",
            " Current loss 2.833176722560893e-06\n",
            "\n",
            "tensor([ 9.6102e-01, -2.7565e-01, -5.2334e-04,  5.0301e+01,  2.7507e-01,\n",
            "         9.6097e-01, -8.0098e-04, -3.7905e+01, -5.0076e-04,  4.5269e-04,\n",
            "         1.0001e+00,  1.7792e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 161\n",
            " Current loss 2.849488964784541e-06\n",
            "\n",
            "tensor([ 9.6098e-01, -2.7560e-01, -5.3275e-04,  5.0302e+01,  2.7521e-01,\n",
            "         9.6118e-01, -6.8618e-04, -3.7905e+01, -5.3034e-04,  3.0382e-04,\n",
            "         1.0000e+00,  3.1213e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 162\n",
            " Current loss 5.269690518616699e-06\n",
            "\n",
            "tensor([ 9.6094e-01, -2.7555e-01, -5.1567e-04,  5.0302e+01,  2.7535e-01,\n",
            "         9.6138e-01, -5.7735e-04, -3.7905e+01, -5.5466e-04,  1.5400e-04,\n",
            "         9.9985e-01,  4.2818e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 163\n",
            " Current loss 5.831803719047457e-06\n",
            "\n",
            "tensor([ 9.6090e-01, -2.7549e-01, -4.8474e-04,  5.0301e+01,  2.7548e-01,\n",
            "         9.6155e-01, -4.7685e-04, -3.7905e+01, -5.7325e-04,  1.6578e-05,\n",
            "         9.9970e-01,  5.1940e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 164\n",
            " Current loss 3.799228124989895e-06\n",
            "\n",
            "tensor([ 9.6085e-01, -2.7546e-01, -4.4925e-04,  5.0301e+01,  2.7560e-01,\n",
            "         9.6169e-01, -3.8566e-04, -3.7904e+01, -5.7895e-04, -1.0605e-04,\n",
            "         9.9957e-01,  5.8602e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 165\n",
            " Current loss 1.932835630213958e-06\n",
            "\n",
            "tensor([ 9.6083e-01, -2.7545e-01, -4.2495e-04,  5.0300e+01,  2.7567e-01,\n",
            "         9.6177e-01, -3.1736e-04, -3.7903e+01, -5.7272e-04, -1.8908e-04,\n",
            "         9.9950e-01,  6.2422e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 166\n",
            " Current loss 2.1785276658192743e-06\n",
            "\n",
            "tensor([ 9.6082e-01, -2.7546e-01, -4.1017e-04,  5.0299e+01,  2.7572e-01,\n",
            "         9.6182e-01, -2.5576e-04, -3.7903e+01, -5.5313e-04, -2.5541e-04,\n",
            "         9.9945e-01,  6.4165e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 167\n",
            " Current loss 3.4037097975669894e-06\n",
            "\n",
            "tensor([ 9.6082e-01, -2.7548e-01, -4.0729e-04,  5.0299e+01,  2.7575e-01,\n",
            "         9.6185e-01, -1.9774e-04, -3.7903e+01, -5.1923e-04, -3.0361e-04,\n",
            "         9.9944e-01,  6.4499e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 168\n",
            " Current loss 4.1128150769509375e-06\n",
            "\n",
            "tensor([ 9.6085e-01, -2.7553e-01, -4.1800e-04,  5.0299e+01,  2.7576e-01,\n",
            "         9.6185e-01, -1.4305e-04, -3.7903e+01, -4.7293e-04, -3.2939e-04,\n",
            "         9.9947e-01,  6.3113e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 169\n",
            " Current loss 3.5080201996606775e-06\n",
            "\n",
            "tensor([ 9.6089e-01, -2.7559e-01, -4.3632e-04,  5.0300e+01,  2.7575e-01,\n",
            "         9.6182e-01, -9.4101e-05, -3.7903e+01, -4.1565e-04, -3.4324e-04,\n",
            "         9.9952e-01,  6.0629e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 170\n",
            " Current loss 2.236045475001447e-06\n",
            "\n",
            "tensor([ 9.6093e-01, -2.7565e-01, -4.5941e-04,  5.0300e+01,  2.7573e-01,\n",
            "         9.6178e-01, -5.1349e-05, -3.7904e+01, -3.5265e-04, -3.3896e-04,\n",
            "         9.9959e-01,  5.6998e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 171\n",
            " Current loss 1.4559501551048015e-06\n",
            "\n",
            "tensor([ 9.6099e-01, -2.7572e-01, -4.8177e-04,  5.0301e+01,  2.7570e-01,\n",
            "         9.6173e-01, -1.6466e-05, -3.7904e+01, -2.8870e-04, -3.2179e-04,\n",
            "         9.9968e-01,  5.2365e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 172\n",
            " Current loss 1.5693318573539727e-06\n",
            "\n",
            "tensor([ 9.6104e-01, -2.7578e-01, -4.9863e-04,  5.0301e+01,  2.7567e-01,\n",
            "         9.6166e-01,  1.1489e-05, -3.7904e+01, -2.2617e-04, -2.9699e-04,\n",
            "         9.9977e-01,  4.6848e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 173\n",
            " Current loss 1.9537369553290773e-06\n",
            "\n",
            "tensor([ 9.6109e-01, -2.7584e-01, -5.0810e-04,  5.0301e+01,  2.7563e-01,\n",
            "         9.6159e-01,  3.0622e-05, -3.7904e+01, -1.6746e-04, -2.6408e-04,\n",
            "         9.9985e-01,  4.0735e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 174\n",
            " Current loss 1.855870891631639e-06\n",
            "\n",
            "tensor([ 9.6113e-01, -2.7588e-01, -5.0158e-04,  5.0301e+01,  2.7560e-01,\n",
            "         9.6151e-01,  4.3303e-05, -3.7904e+01, -1.1495e-04, -2.3068e-04,\n",
            "         9.9993e-01,  3.4430e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 175\n",
            " Current loss 1.2031176765958662e-06\n",
            "\n",
            "tensor([ 9.6116e-01, -2.7590e-01, -4.8242e-04,  5.0300e+01,  2.7557e-01,\n",
            "         9.6144e-01,  5.0023e-05, -3.7904e+01, -6.9596e-05, -1.9252e-04,\n",
            "         1.0000e+00,  2.7766e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 176\n",
            " Current loss 5.6486499033781e-07\n",
            "\n",
            "tensor([ 9.6119e-01, -2.7592e-01, -4.4776e-04,  5.0300e+01,  2.7556e-01,\n",
            "         9.6138e-01,  5.1975e-05, -3.7904e+01, -3.1874e-05, -1.5483e-04,\n",
            "         1.0001e+00,  2.1151e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 177\n",
            " Current loss 4.3165181295989896e-07\n",
            "\n",
            "tensor([ 9.6122e-01, -2.7591e-01, -4.0260e-04,  5.0300e+01,  2.7555e-01,\n",
            "         9.6133e-01,  5.1051e-05, -3.7904e+01, -3.5763e-07, -1.1666e-04,\n",
            "         1.0001e+00,  1.4703e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 178\n",
            " Current loss 7.11148857135413e-07\n",
            "\n",
            "tensor([ 9.6125e-01, -2.7590e-01, -3.4814e-04,  5.0299e+01,  2.7555e-01,\n",
            "         9.6130e-01,  4.9651e-05, -3.7903e+01,  2.4952e-05, -8.0399e-05,\n",
            "         1.0001e+00,  8.5652e-05], grad_fn=<AddBackward0>)\n",
            "Epoch number 179\n",
            " Current loss 9.21339506021468e-07\n",
            "\n",
            "tensor([ 9.6127e-01, -2.7586e-01, -2.8438e-04,  5.0299e+01,  2.7557e-01,\n",
            "         9.6128e-01,  4.8727e-05, -3.7904e+01,  4.5493e-05, -4.9382e-05,\n",
            "         1.0002e+00,  2.9288e-05], grad_fn=<AddBackward0>)\n",
            "Epoch number 180\n",
            " Current loss 7.411417755065486e-07\n",
            "\n",
            "tensor([ 9.6129e-01, -2.7583e-01, -2.2851e-04,  5.0300e+01,  2.7558e-01,\n",
            "         9.6127e-01,  4.6834e-05, -3.7904e+01,  5.6960e-05, -2.5526e-05,\n",
            "         1.0002e+00, -1.1791e-05], grad_fn=<AddBackward0>)\n",
            "Epoch number 181\n",
            " Current loss 4.1796667460403114e-07\n",
            "\n",
            "tensor([ 9.6131e-01, -2.7580e-01, -1.6906e-04,  5.0300e+01,  2.7561e-01,\n",
            "         9.6128e-01,  4.6372e-05, -3.7904e+01,  6.4135e-05, -4.0531e-06,\n",
            "         1.0002e+00, -4.6663e-05], grad_fn=<AddBackward0>)\n",
            "Epoch number 182\n",
            " Current loss 1.7336596158656903e-07\n",
            "\n",
            "tensor([ 9.6132e-01, -2.7575e-01, -1.0748e-04,  5.0300e+01,  2.7563e-01,\n",
            "         9.6128e-01,  4.4003e-05, -3.7904e+01,  6.7972e-05,  1.0267e-05,\n",
            "         1.0002e+00, -7.7236e-05], grad_fn=<AddBackward0>)\n",
            "Epoch number 183\n",
            " Current loss 1.489570422563702e-07\n",
            "\n",
            "tensor([ 9.6133e-01, -2.7571e-01, -4.3750e-05,  5.0300e+01,  2.7566e-01,\n",
            "         9.6129e-01,  4.3541e-05, -3.7904e+01,  6.7987e-05,  2.4110e-05,\n",
            "         1.0002e+00, -1.0256e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 184\n",
            " Current loss 2.943244794550992e-07\n",
            "\n",
            "tensor([ 9.6133e-01, -2.7566e-01,  1.5441e-05,  5.0300e+01,  2.7569e-01,\n",
            "         9.6130e-01,  4.2841e-05, -3.7904e+01,  6.5140e-05,  2.9840e-05,\n",
            "         1.0002e+00, -1.2358e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 185\n",
            " Current loss 4.1320322452520486e-07\n",
            "\n",
            "tensor([ 9.6132e-01, -2.7562e-01,  7.2483e-05,  5.0300e+01,  2.7572e-01,\n",
            "         9.6131e-01,  3.9518e-05, -3.7904e+01,  6.0856e-05,  3.7000e-05,\n",
            "         1.0001e+00, -1.3983e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 186\n",
            " Current loss 3.8418494341385667e-07\n",
            "\n",
            "tensor([ 9.6132e-01, -2.7558e-01,  1.2594e-04,  5.0300e+01,  2.7574e-01,\n",
            "         9.6131e-01,  3.9518e-05, -3.7904e+01,  5.2281e-05,  3.9391e-05,\n",
            "         1.0001e+00, -1.5010e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 187\n",
            " Current loss 2.519273039069958e-07\n",
            "\n",
            "tensor([ 9.6131e-01, -2.7554e-01,  1.6937e-04,  5.0300e+01,  2.7575e-01,\n",
            "         9.6131e-01,  3.8803e-05, -3.7904e+01,  4.6089e-05,  3.8922e-05,\n",
            "         1.0001e+00, -1.5680e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 188\n",
            " Current loss 1.4280202265126718e-07\n",
            "\n",
            "tensor([ 9.6130e-01, -2.7551e-01,  2.0493e-04,  5.0300e+01,  2.7577e-01,\n",
            "         9.6131e-01,  3.7372e-05, -3.7904e+01,  3.8944e-05,  3.7499e-05,\n",
            "         1.0001e+00, -1.5991e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 189\n",
            " Current loss 1.4077133414502896e-07\n",
            "\n",
            "tensor([ 9.6129e-01, -2.7549e-01,  2.3118e-04,  5.0300e+01,  2.7577e-01,\n",
            "         9.6130e-01,  3.6657e-05, -3.7904e+01,  3.4183e-05,  3.5115e-05,\n",
            "         1.0001e+00, -1.5753e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 190\n",
            " Current loss 2.2959426360102952e-07\n",
            "\n",
            "tensor([ 9.6128e-01, -2.7548e-01,  2.4551e-04,  5.0300e+01,  2.7577e-01,\n",
            "         9.6129e-01,  3.9279e-05, -3.7904e+01,  3.0369e-05,  3.0346e-05,\n",
            "         1.0000e+00, -1.5371e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 191\n",
            " Current loss 3.0059882760724577e-07\n",
            "\n",
            "tensor([ 9.6128e-01, -2.7548e-01,  2.5076e-04,  5.0300e+01,  2.7577e-01,\n",
            "         9.6128e-01,  4.3094e-05, -3.7904e+01,  2.9415e-05,  2.4624e-05,\n",
            "         1.0000e+00, -1.4465e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 192\n",
            " Current loss 2.983539104661759e-07\n",
            "\n",
            "tensor([ 9.6128e-01, -2.7549e-01,  2.4814e-04,  5.0300e+01,  2.7577e-01,\n",
            "         9.6126e-01,  4.6432e-05, -3.7904e+01,  3.0845e-05,  2.3194e-05,\n",
            "         1.0000e+00, -1.3510e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 193\n",
            " Current loss 2.1881693612613162e-07\n",
            "\n",
            "tensor([ 9.6127e-01, -2.7550e-01,  2.3359e-04,  5.0300e+01,  2.7575e-01,\n",
            "         9.6124e-01,  5.2154e-05, -3.7904e+01,  3.3230e-05,  1.7472e-05,\n",
            "         1.0000e+00, -1.2292e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 194\n",
            " Current loss 1.287247783920975e-07\n",
            "\n",
            "tensor([ 9.6127e-01, -2.7552e-01,  2.1689e-04,  5.0300e+01,  2.7574e-01,\n",
            "         9.6122e-01,  5.7638e-05, -3.7904e+01,  3.6567e-05,  1.5087e-05,\n",
            "         1.0000e+00, -1.0789e-04], grad_fn=<AddBackward0>)\n",
            "Epoch number 195\n",
            " Current loss 9.538121048535686e-08\n",
            "\n",
            "tensor([ 9.6128e-01, -2.7554e-01,  1.9733e-04,  5.0300e+01,  2.7572e-01,\n",
            "         9.6120e-01,  6.0499e-05, -3.7904e+01,  3.9428e-05,  1.4134e-05,\n",
            "         1.0000e+00, -9.8336e-05], grad_fn=<AddBackward0>)\n",
            "Epoch number 196\n",
            " Current loss 1.1027249513517745e-07\n",
            "\n",
            "tensor([ 9.6128e-01, -2.7556e-01,  1.7634e-04,  5.0300e+01,  2.7571e-01,\n",
            "         9.6118e-01,  6.5982e-05, -3.7904e+01,  4.3720e-05,  1.1273e-05,\n",
            "         1.0000e+00, -8.7116e-05], grad_fn=<AddBackward0>)\n",
            "Epoch number 197\n",
            " Current loss 1.282524095813642e-07\n",
            "\n",
            "tensor([ 9.6128e-01, -2.7557e-01,  1.5415e-04,  5.0300e+01,  2.7569e-01,\n",
            "         9.6117e-01,  6.9559e-05, -3.7904e+01,  4.6104e-05,  8.4117e-06,\n",
            "         1.0000e+00, -7.3511e-05], grad_fn=<AddBackward0>)\n",
            "Epoch number 198\n",
            " Current loss 1.2803137394712394e-07\n",
            "\n",
            "tensor([ 9.6128e-01, -2.7559e-01,  1.3434e-04,  5.0300e+01,  2.7568e-01,\n",
            "         9.6115e-01,  6.9797e-05, -3.7904e+01,  4.8488e-05,  9.3654e-06,\n",
            "         1.0000e+00, -6.3002e-05], grad_fn=<AddBackward0>)\n",
            "Epoch number 199\n",
            " Current loss 9.983808979541209e-08\n",
            "\n",
            "Best loss 9.538121048535686e-08\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "best_loss = np.inf\n",
        "loss_history = [] \n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "#iteration_number= 0\n",
        "\n",
        "# Iterate throught the epochs\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Iterate over batches\n",
        "#    for i, (img0, img1, label) in enumerate(train_dataloader, 0):\n",
        "\n",
        "        # Send the images and labels to CUDA\n",
        " #       img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
        "  \n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Pass in the two images into the network and obtain two outputs\n",
        "        res = model(x, y)\n",
        "        #print(res.shape)\n",
        "        print(res)\n",
        "        # Pass the outputs of the networks and label into the loss function\n",
        "        loss = criterion(res, matrix.flatten())\n",
        "        # Calculate the backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "        scheduler.step() \n",
        "        # Every 10 batches print out the loss\n",
        "#        if i % 10 == 0 :\n",
        "        print(f\"Epoch number {epoch}\\n Current loss {loss.item()}\\n\")\n",
        "        #iteration_number += 10\n",
        "\n",
        "        if best_loss > loss:\n",
        "          best_loss = loss\n",
        "          best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "\n",
        "\n",
        "print(f'Best loss {best_loss}')\n",
        "\n",
        "plt.plot(range(num_epochs),loss_history)\n",
        "plt.show()\n",
        "model.load_state_dict(best_model_wts)\n",
        "#y.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the input and output\n",
        "print('the input')\n",
        "fig = plt.subplots(1,2)\n",
        "plt.subplot(1,2,1)\n",
        "x_to_print = x[0].numpy()\n",
        "x_to_print = x_to_print.transpose(1, 2, 0)\n",
        "plt.imshow(x_to_print[:,:,10])\n",
        "plt.subplot(1,2,2)\n",
        "y_to_print = y[0].numpy()\n",
        "y_to_print = y_to_print.transpose(1, 2, 0)\n",
        "plt.imshow(y_to_print[:,:,10])\n",
        "\n",
        "\n",
        "print('the output of the model')\n",
        "model.load_state_dict(best_model_wts)\n",
        "result_matrix = model(x, y)\n"
      ],
      "metadata": {
        "id": "orRgERYAMyxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c39b21-d8df-4c40-a9a2-e7a0c0091eee"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 9.8147e-01, -8.1401e-03,  5.1716e-03,  1.1570e+01,  7.4433e-02,\n",
              "          1.0004e+00, -2.1785e-02, -1.0747e+01, -5.9782e-03, -1.8252e-02,\n",
              "          1.0093e+00,  2.6488e-02],\n",
              "        [ 9.7994e-01, -8.4565e-03,  4.6730e-03,  1.1575e+01,  7.3543e-02,\n",
              "          1.0003e+00, -2.2586e-02, -1.0752e+01, -6.4863e-03, -1.8585e-02,\n",
              "          1.0096e+00,  2.7398e-02]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Variant2 (Siamese network)"
      ],
      "metadata": {
        "id": "dheVNuKtcUvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Siam_AirNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Siam_AirNet, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.firstlayer = nn.Sequential(\n",
        "            #how many channels do we have?? \n",
        "            nn.Conv2d(in_channels=20,out_channels=20,kernel_size=3,stride=1,padding=1),\n",
        "            #(320 - 3 + 2*1)/1 + 1 = 320\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n",
        "            #(320 - 2)/2 + 1 = 160\n",
        "        self.transition = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=20,out_channels=20,kernel_size=1,stride=1,padding=0),\n",
        "            #(160 - 1 )/1 + 1 \n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n",
        "            #80\n",
        "        self.regression = nn.Sequential(\n",
        "            #we have to double here because the images will be concatenated\n",
        "            nn.Linear(20*20*20*2, 1024),\n",
        "            #nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "           # nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(512, 128),\n",
        "           # nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(128, 64),\n",
        "           # nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(64, 12))   \n",
        "\n",
        "    def forward_once(self, x):\n",
        "        # This function will be called for both images\n",
        "        # Its output is used to determine the similiarity\n",
        "        output = self.firstlayer(x)\n",
        "        output = self.transition(output)\n",
        "        output = self.transition(output)\n",
        "        output = self.transition(output)\n",
        "        output = self.flatten(output)        \n",
        "        return output\n",
        "\n",
        "    def forward(self, input_t, input_ref):\n",
        "        # In this function we pass in both images and obtain both vectors\n",
        "        # which are returned\n",
        "        input_t = self.forward_once(input_t)\n",
        "        #print(input_t.shape)\n",
        "        input_ref = self.forward_once(input_ref)\n",
        "        #print(input_ref.shape)\n",
        "        input_conc = torch.cat((input_t,input_ref),dim=1)\n",
        "        #print(input_conc.shape)\n",
        "        res = self.regression(input_conc)\n",
        "        return res "
      ],
      "metadata": {
        "id": "toTK-us-3WzB"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zZTazLXI3WsC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "zH3A0M96MzBB"
      },
      "outputs": [],
      "source": [
        "model2 = Siam_AirNet()\n",
        "model2.train()\n",
        "criterion = nn.MSELoss(reduction='sum')\n",
        "optimizer = optim.Adam(model2.parameters(), lr = 0.005 )\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.8)\n",
        "num_epochs = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e34109ed-97da-4b4e-de9d-1029d60e81e4",
        "id": "1_7NrLPUMzBB"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1079,  0.0009, -0.0952,  0.0891, -0.0733,  0.0927,  0.0824, -0.1054,\n",
            "         -0.1101,  0.0119, -0.0752, -0.0270]], grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([1, 12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch number 0\n",
            " Current loss 26348.10546875\n",
            "\n",
            "tensor([[ 15.4814,  14.5704,   8.2264, -16.1322,   6.2891,   8.9244,   5.1405,\n",
            "          24.5399,   5.4251,  15.3138, -11.5637, -12.7230]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 1\n",
            " Current loss 18968.14453125\n",
            "\n",
            "tensor([[  26.5406,   69.8647,  -12.1354, -116.7974,   11.8034,   26.3585,\n",
            "           44.7188,  208.6897,   33.9906,   46.6249,  -53.7789,  -59.4159]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 2\n",
            " Current loss 24520.640625\n",
            "\n",
            "tensor([[ -0.5456,  10.2963,  -3.6010, -30.9974,   1.3422,   2.8710,   3.7563,\n",
            "          51.1311,   6.0065,   4.6719,  -8.0542, -10.6681]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 3\n",
            " Current loss 11020.5224609375\n",
            "\n",
            "tensor([[ -2.7820,  -2.8595,   3.1795, -21.6360,  -0.7896,  -0.9539,  -5.1768,\n",
            "          31.2544,   4.2808,  -1.1658,  -2.8272,  -3.5445]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 4\n",
            " Current loss 15742.943359375\n",
            "\n",
            "tensor([[-2.1018e+00, -8.2956e+00,  9.2728e+00, -2.7243e+01, -2.2259e+00,\n",
            "         -5.1044e+00, -1.0737e+01,  4.0028e+01,  5.8333e+00, -5.0441e+00,\n",
            "          9.8938e-03, -2.9751e+00]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 5\n",
            " Current loss 13586.93359375\n",
            "\n",
            "tensor([[ -2.3746, -14.8990,  20.3372, -51.0474,  -5.1545, -13.0306, -21.3069,\n",
            "          74.9080,   7.7518, -13.3769,   5.0527,  -1.2732]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 6\n",
            " Current loss 7174.6279296875\n",
            "\n",
            "tensor([[ -6.6177, -30.1016,  32.4509, -97.4517,  -8.9723, -24.1473, -36.6995,\n",
            "         156.7389,   7.2698, -29.2176,  12.0710,   8.0901]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 7\n",
            " Current loss 6249.05517578125\n",
            "\n",
            "tensor([[ -9.1868, -29.4291,   6.7846, -80.7250,  -7.8785, -15.3846, -19.4192,\n",
            "         168.2908,  -4.7306, -24.7609,   9.8263,  19.8311]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 8\n",
            " Current loss 3469.60302734375\n",
            "\n",
            "tensor([[ -3.6942, -18.0033, -11.8025, -46.0026,  -4.6231,  -3.1031,   0.5607,\n",
            "         135.3195, -14.6107, -13.4574,   7.2211,  18.8206]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 9\n",
            " Current loss 1889.1588134765625\n",
            "\n",
            "tensor([[  1.2029,  -7.9072, -15.2169, -33.2769,  -2.1729,   4.2103,   8.7839,\n",
            "         119.6050, -18.8104,  -6.4797,   5.1969,  13.3250]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 10\n",
            " Current loss 2871.45361328125\n",
            "\n",
            "tensor([[  6.6067,  -0.5294, -11.7494, -35.7361,  -0.3026,   8.7639,  11.1763,\n",
            "         129.1200, -22.7363,  -2.6148,   5.2952,   7.2240]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 11\n",
            " Current loss 2233.82373046875\n",
            "\n",
            "tensor([[ 12.0430,   5.5935,  -3.2362, -48.2627,   2.7522,  13.1085,  11.3635,\n",
            "         155.7663, -24.1472,   0.7679,   4.2116,  -0.9484]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 12\n",
            " Current loss 1422.2630615234375\n",
            "\n",
            "tensor([[ 10.7608,   9.8745,   5.6371, -63.1597,   5.5168,  13.5211,   6.8687,\n",
            "         171.2561, -17.4146,   4.4555,  -1.0798,  -5.6353]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 13\n",
            " Current loss 1366.1942138671875\n",
            "\n",
            "tensor([[  3.1938,  10.2195,   8.1123, -67.9250,   4.2287,   9.3692,   0.5258,\n",
            "         154.8767,  -5.6828,   6.8662,  -6.9116,  -4.8800]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 14\n",
            " Current loss 476.53460693359375\n",
            "\n",
            "tensor([[ -3.8573,   7.1344,   5.7048, -65.2501,   2.5062,   4.9617,  -3.9488,\n",
            "         131.1166,   5.1856,   7.5881,  -9.6684,  -2.3065]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 15\n",
            " Current loss 633.4952392578125\n",
            "\n",
            "tensor([[ -6.4244,   7.1614,   3.0809, -66.5189,  -0.6733,   0.5045,  -5.5578,\n",
            "         127.5302,   9.6524,   7.2343,  -9.3198,  -1.5729]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 16\n",
            " Current loss 814.2442626953125\n",
            "\n",
            "tensor([[ -7.1387,   7.2262,   0.7981, -71.6988,  -3.3307,  -3.3349,  -5.8956,\n",
            "         137.0462,  12.7820,   7.3448,  -7.4239,  -2.0156]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 17\n",
            " Current loss 612.92919921875\n",
            "\n",
            "tensor([[ -5.8389,   6.1568,  -1.0705, -76.8752,  -4.7718,  -6.3329,  -4.7835,\n",
            "         150.8158,  15.0918,   7.6105,  -4.0311,  -3.0114]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 18\n",
            " Current loss 610.5475463867188\n",
            "\n",
            "tensor([[-1.8538e+00,  4.9516e+00, -2.0925e+00, -7.5151e+01, -4.1718e+00,\n",
            "         -8.6492e+00, -2.2101e+00,  1.5513e+02,  1.5566e+01,  5.9702e+00,\n",
            "          1.3561e-01, -3.4768e+00]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 19\n",
            " Current loss 558.5690307617188\n",
            "\n",
            "tensor([[  0.9478,   3.2478,  -3.4786, -69.0453,  -2.8697,  -7.4931,   0.2747,\n",
            "         148.4808,  12.2091,   4.5366,   4.2194,  -3.2755]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 20\n",
            " Current loss 291.8805236816406\n",
            "\n",
            "tensor([[  2.6546,   1.9128,  -4.3153, -63.1302,  -1.1963,  -4.9247,   2.2475,\n",
            "         139.9358,   7.8831,   2.9101,   6.9692,  -2.6179]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 21\n",
            " Current loss 250.0035858154297\n",
            "\n",
            "tensor([[  3.7388,   0.9890,  -4.3985, -61.0846,   0.5448,  -2.1494,   3.9658,\n",
            "         138.4147,   4.2093,   1.3576,   8.4201,  -2.0027]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 22\n",
            " Current loss 251.35635375976562\n",
            "\n",
            "tensor([[  4.0350,   0.1824,  -4.0536, -63.6181,   1.9283,   1.0580,   5.4428,\n",
            "         145.2549,   0.8327,   0.1622,   9.0388,  -1.4789]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 23\n",
            " Current loss 145.43397521972656\n",
            "\n",
            "tensor([[  3.5636,  -0.3966,  -3.1702, -67.9673,   2.5937,   4.4274,   6.3268,\n",
            "         154.3936,  -2.3981,  -0.9719,   8.5556,  -0.7479]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 24\n",
            " Current loss 190.63037109375\n",
            "\n",
            "tensor([[  2.5546,  -0.4778,  -1.8238, -68.7111,   2.0170,   6.6855,   5.9050,\n",
            "         154.4019,  -4.8638,  -2.1350,   6.7027,   0.5244]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 25\n",
            " Current loss 192.86557006835938\n",
            "\n",
            "tensor([[  1.5183,  -0.2915,  -0.2570, -65.9714,   0.6323,   7.2946,   4.5965,\n",
            "         146.9233,  -6.0766,  -3.0308,   4.2420,   1.7584]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 26\n",
            " Current loss 128.5706787109375\n",
            "\n",
            "tensor([[  0.7977,  -0.2690,   1.3745, -63.5735,  -0.8227,   6.8319,   3.2144,\n",
            "         141.1766,  -6.2443,  -3.4156,   1.9446,   2.4405]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 27\n",
            " Current loss 162.15853881835938\n",
            "\n",
            "tensor([[ 3.7725e-01, -5.5136e-01,  2.9815e+00, -6.3822e+01, -2.0778e+00,\n",
            "          5.8284e+00,  2.0734e+00,  1.4236e+02, -5.7445e+00, -3.3907e+00,\n",
            "         -2.5191e-02,  2.5225e+00]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 28\n",
            " Current loss 132.72132873535156\n",
            "\n",
            "tensor([[  0.1668,  -1.0479,   4.3711, -66.1463,  -3.0903,   4.3521,   1.1240,\n",
            "         149.1644,  -4.7629,  -3.1066,  -1.7095,   2.1294]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 29\n",
            " Current loss 87.79603576660156\n",
            "\n",
            "tensor([[ 8.7282e-02, -1.5232e+00,  5.0503e+00, -6.7404e+01, -3.4515e+00,\n",
            "          2.3914e+00,  1.9138e-01,  1.5405e+02, -3.3309e+00, -2.5647e+00,\n",
            "         -2.9710e+00,  1.5854e+00]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 30\n",
            " Current loss 114.03778076171875\n",
            "\n",
            "tensor([[ 1.1273e-01, -1.7197e+00,  4.8097e+00, -6.5929e+01, -3.0165e+00,\n",
            "          6.6423e-01, -4.8918e-01,  1.5227e+02, -2.0180e+00, -2.0488e+00,\n",
            "         -3.4579e+00,  1.1609e+00]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 31\n",
            " Current loss 81.3603515625\n",
            "\n",
            "tensor([[  0.1839,  -1.7301,   4.0786, -63.3819,  -2.2336,  -0.8070,  -1.0848,\n",
            "         147.4184,  -0.8427,  -1.5309,  -3.4056,   0.6479]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 32\n",
            " Current loss 58.828643798828125\n",
            "\n",
            "tensor([[ 2.2607e-01, -1.5660e+00,  3.0018e+00, -6.1910e+01, -1.4838e+00,\n",
            "         -1.8390e+00, -1.6542e+00,  1.4425e+02,  5.6739e-03, -1.0298e+00,\n",
            "         -2.9965e+00,  2.3419e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 33\n",
            " Current loss 73.16903686523438\n",
            "\n",
            "tensor([[ 2.2310e-01, -1.2776e+00,  1.7416e+00, -6.2510e+01, -8.6397e-01,\n",
            "         -2.4949e+00, -2.2029e+00,  1.4521e+02,  5.8232e-01, -5.5806e-01,\n",
            "         -2.4048e+00, -9.9501e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 34\n",
            " Current loss 55.36533737182617\n",
            "\n",
            "tensor([[ 1.9800e-01, -8.8005e-01,  3.5691e-01, -6.4562e+01, -3.4699e-01,\n",
            "         -2.8012e+00, -2.7029e+00,  1.4895e+02,  9.5395e-01, -8.2825e-02,\n",
            "         -1.6685e+00, -3.5223e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 35\n",
            " Current loss 33.54309844970703\n",
            "\n",
            "tensor([[ 2.2867e-01, -3.7937e-01, -1.0017e+00, -6.6521e+01,  5.1475e-02,\n",
            "         -2.7125e+00, -3.0910e+00,  1.5199e+02,  1.1208e+00,  3.7675e-01,\n",
            "         -7.6690e-01, -5.0506e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 36\n",
            " Current loss 44.17237091064453\n",
            "\n",
            "tensor([[  0.3520,   0.1581,  -2.1307, -67.0196,   0.3449,  -2.3043,  -3.2276,\n",
            "         151.5606,   1.0949,   0.7790,   0.2216,  -0.5666]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 37\n",
            " Current loss 41.11307144165039\n",
            "\n",
            "tensor([[  0.5112,   0.5716,  -2.8650, -66.0418,   0.5304,  -1.5345,  -3.0669,\n",
            "         147.8732,   1.0163,   1.1371,   1.0540,  -0.5852]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 38\n",
            " Current loss 27.061935424804688\n",
            "\n",
            "tensor([[  0.7317,   0.8926,  -3.1587, -65.1557,   0.5627,  -0.6835,  -2.7271,\n",
            "         144.7178,   0.9075,   1.4549,   1.7344,  -0.6103]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 39\n",
            " Current loss 37.35559844970703\n",
            "\n",
            "tensor([[ 1.0272e+00,  1.2490e+00, -3.1069e+00, -6.5618e+01,  3.9096e-01,\n",
            "          7.9654e-02, -2.3357e+00,  1.4486e+02,  7.3817e-01,  1.6506e+00,\n",
            "          2.3845e+00, -6.5725e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 40\n",
            " Current loss 33.726890563964844\n",
            "\n",
            "tensor([[ 1.3298e+00,  1.5839e+00, -2.7718e+00, -6.7065e+01,  8.7525e-02,\n",
            "          7.7366e-01, -1.8498e+00,  1.4751e+02,  5.9297e-01,  1.7567e+00,\n",
            "          2.9164e+00, -7.2112e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 41\n",
            " Current loss 22.117141723632812\n",
            "\n",
            "tensor([[  1.5571,   1.7962,  -2.1706, -68.2061,  -0.2397,   1.4083,  -1.2042,\n",
            "         149.9348,   0.5234,   1.7490,   3.1917,  -0.7852]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 42\n",
            " Current loss 25.658565521240234\n",
            "\n",
            "tensor([[  1.6493,   1.8193,  -1.3661, -68.0028,  -0.4939,   1.9389,  -0.4158,\n",
            "         149.8680,   0.5444,   1.5985,   3.1219,  -0.8186]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 43\n",
            " Current loss 20.749767303466797\n",
            "\n",
            "tensor([[  1.5920,   1.7049,  -0.5095, -66.6813,  -0.6556,   2.2995,   0.4080,\n",
            "         147.6965,   0.6211,   1.3079,   2.7655,  -0.7985]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 44\n",
            " Current loss 11.219871520996094\n",
            "\n",
            "tensor([[  1.4002,   1.5628,   0.2434, -65.4173,  -0.7691,   2.4771,   1.1709,\n",
            "         145.8242,   0.7062,   0.9226,   2.2582,  -0.7268]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 45\n",
            " Current loss 14.882707595825195\n",
            "\n",
            "tensor([[  1.1609,   1.5053,   0.6960, -65.2007,  -0.8768,   2.4862,   1.6834,\n",
            "         146.0735,   0.7337,   0.5660,   1.8356,  -0.6318]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 46\n",
            " Current loss 14.155920028686523\n",
            "\n",
            "tensor([[  0.8623,   1.5145,   0.9980, -65.7007,  -1.0143,   2.3733,   2.0712,\n",
            "         147.8179,   0.6959,   0.1768,   1.4379,  -0.4970]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 47\n",
            " Current loss 9.930094718933105\n",
            "\n",
            "tensor([[  0.5482,   1.5673,   1.1619, -66.3123,  -1.1620,   2.1413,   2.2921,\n",
            "         149.6508,   0.5784,  -0.2273,   1.0919,  -0.3180]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 48\n",
            " Current loss 12.49271011352539\n",
            "\n",
            "tensor([[ 2.7939e-01,  1.6287e+00,  1.2092e+00, -6.6408e+01, -1.2903e+00,\n",
            "          1.8046e+00,  2.3038e+00,  1.5012e+02,  3.8030e-01, -6.1107e-01,\n",
            "          8.3588e-01, -1.0268e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 49\n",
            " Current loss 14.02322006225586\n",
            "\n",
            "tensor([[ 1.0026e-01,  1.6598e+00,  1.1673e+00, -6.5882e+01, -1.3665e+00,\n",
            "          1.4116e+00,  2.1168e+00,  1.4899e+02,  1.3422e-01, -9.2266e-01,\n",
            "          6.9074e-01,  1.2287e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 50\n",
            " Current loss 9.843600273132324\n",
            "\n",
            "tensor([[ 1.4411e-02,  1.6312e+00,  1.0608e+00, -6.5204e+01, -1.3679e+00,\n",
            "          1.0275e+00,  1.7996e+00,  1.4735e+02, -1.0502e-01, -1.1204e+00,\n",
            "          6.3878e-01,  3.2860e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 51\n",
            " Current loss 9.129674911499023\n",
            "\n",
            "tensor([[ 1.0531e-03,  1.5282e+00,  9.0752e-01, -6.4956e+01, -1.2864e+00,\n",
            "          6.9979e-01,  1.4294e+00,  1.4658e+02, -2.9065e-01, -1.1885e+00,\n",
            "          6.4192e-01,  4.9577e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 52\n",
            " Current loss 9.926276206970215\n",
            "\n",
            "tensor([[ 3.6744e-02,  1.3275e+00,  7.1786e-01, -6.5335e+01, -1.1017e+00,\n",
            "          4.5683e-01,  1.0718e+00,  1.4721e+02, -3.8167e-01, -1.1277e+00,\n",
            "          6.4507e-01,  6.1330e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 53\n",
            " Current loss 6.08107852935791\n",
            "\n",
            "tensor([[ 1.1991e-01,  1.0218e+00,  5.0797e-01, -6.6043e+01, -8.1699e-01,\n",
            "          3.0467e-01,  7.4772e-01,  1.4862e+02, -3.6974e-01, -9.5123e-01,\n",
            "          6.2625e-01,  6.7422e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 54\n",
            " Current loss 3.403346061706543\n",
            "\n",
            "tensor([[  0.2785,   0.6669,   0.3099, -66.5396,  -0.5210,   0.2179,   0.4104,\n",
            "         149.5542,  -0.3148,  -0.6908,   0.6490,   0.6813]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 55\n",
            " Current loss 4.223400115966797\n",
            "\n",
            "tensor([[ 5.0048e-01,  3.0682e-01,  1.4148e-01, -6.6477e+01, -2.6835e-01,\n",
            "          1.8578e-01,  6.9236e-02,  1.4923e+02, -2.4435e-01, -3.8962e-01,\n",
            "          7.1405e-01,  6.3865e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 56\n",
            " Current loss 2.802086591720581\n",
            "\n",
            "tensor([[ 7.4837e-01, -9.2065e-03,  2.9415e-03, -6.6011e+01, -1.0628e-01,\n",
            "          1.9387e-01, -2.5346e-01,  1.4802e+02, -1.8045e-01, -9.1329e-02,\n",
            "          8.0785e-01,  5.5694e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 57\n",
            " Current loss 1.5529085397720337\n",
            "\n",
            "tensor([[ 9.7758e-01, -2.4669e-01, -1.2070e-01, -6.5628e+01, -5.6257e-02,\n",
            "          2.2740e-01, -5.3642e-01,  1.4701e+02, -1.3405e-01,  1.7373e-01,\n",
            "          9.0966e-01,  4.4915e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 58\n",
            " Current loss 3.5352251529693604\n",
            "\n",
            "tensor([[ 1.1564e+00, -3.8996e-01, -2.4387e-01, -6.5688e+01, -1.1476e-01,\n",
            "          2.7475e-01, -7.6782e-01,  1.4701e+02, -1.0862e-01,  3.8760e-01,\n",
            "          1.0022e+00,  3.2544e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 59\n",
            " Current loss 4.11982536315918\n",
            "\n",
            "tensor([[ 1.2700e+00, -4.3423e-01, -3.6602e-01, -6.6138e+01, -2.6176e-01,\n",
            "          3.2827e-01, -9.4197e-01,  1.4793e+02, -1.0587e-01,  5.3438e-01,\n",
            "          1.0753e+00,  1.9297e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 60\n",
            " Current loss 3.2757928371429443\n",
            "\n",
            "tensor([[ 1.3061e+00, -3.9236e-01, -4.4874e-01, -6.6489e+01, -4.2277e-01,\n",
            "          3.7199e-01, -1.0308e+00,  1.4869e+02, -1.2208e-01,  5.8442e-01,\n",
            "          1.1141e+00,  8.6025e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 61\n",
            " Current loss 3.838723659515381\n",
            "\n",
            "tensor([[ 1.2913e+00, -2.8337e-01, -5.0276e-01, -6.6588e+01, -5.9724e-01,\n",
            "          4.1502e-01, -1.0661e+00,  1.4893e+02, -1.5262e-01,  5.6353e-01,\n",
            "          1.1314e+00, -1.6450e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 62\n",
            " Current loss 4.047242164611816\n",
            "\n",
            "tensor([[ 1.2325e+00, -1.2569e-01, -5.2066e-01, -6.6376e+01, -7.5411e-01,\n",
            "          4.5781e-01, -1.0469e+00,  1.4852e+02, -1.8811e-01,  4.8081e-01,\n",
            "          1.1262e+00, -1.1003e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 63\n",
            " Current loss 2.9247374534606934\n",
            "\n",
            "tensor([[ 1.1388e+00,  5.8273e-02, -5.0447e-01, -6.6014e+01, -8.6955e-01,\n",
            "          5.0272e-01, -9.7591e-01,  1.4784e+02, -2.1617e-01,  3.5675e-01,\n",
            "          1.0982e+00, -1.9263e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 64\n",
            " Current loss 2.161933183670044\n",
            "\n",
            "tensor([[  1.0197,   0.2484,  -0.4615, -65.7467,  -0.9316,   0.5529,  -0.8590,\n",
            "         147.3966,  -0.2259,   0.2153,   1.0492,  -0.2639]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch number 65\n",
            " Current loss 2.105375051498413\n",
            "\n",
            "tensor([[ 8.8651e-01,  4.3029e-01, -3.9725e-01, -6.5717e+01, -9.3873e-01,\n",
            "          6.1038e-01, -7.0392e-01,  1.4752e+02, -2.1184e-01,  7.6314e-02,\n",
            "          9.8388e-01, -3.2324e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 66\n",
            " Current loss 1.443746566772461\n",
            "\n",
            "tensor([[ 7.5308e-01,  5.9390e-01, -3.1265e-01, -6.5881e+01, -8.9650e-01,\n",
            "          6.7486e-01, -5.2116e-01,  1.4809e+02, -1.7464e-01, -4.7336e-02,\n",
            "          9.1046e-01, -3.6767e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 67\n",
            " Current loss 0.6189305782318115\n",
            "\n",
            "tensor([[ 6.3548e-01,  7.3214e-01, -2.0678e-01, -6.6051e+01, -8.1676e-01,\n",
            "          7.4303e-01, -3.2461e-01,  1.4867e+02, -1.2076e-01, -1.4780e-01,\n",
            "          8.4002e-01, -3.9211e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 68\n",
            " Current loss 0.6740037202835083\n",
            "\n",
            "tensor([[ 5.4774e-01,  8.4086e-01, -8.2971e-02, -6.6053e+01, -7.1765e-01,\n",
            "          8.0970e-01, -1.3063e-01,  1.4885e+02, -5.9795e-02, -2.1996e-01,\n",
            "          7.8385e-01, -3.9171e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 69\n",
            " Current loss 0.8430162668228149\n",
            "\n",
            "tensor([[ 4.9637e-01,  9.2026e-01,  4.7829e-02, -6.5856e+01, -6.2119e-01,\n",
            "          8.7009e-01,  4.5886e-02,  1.4855e+02, -9.3723e-04, -2.6029e-01,\n",
            "          7.4980e-01, -3.6473e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 70\n",
            " Current loss 0.5750268697738647\n",
            "\n",
            "tensor([[ 4.7857e-01,  9.7498e-01,  1.6948e-01, -6.5596e+01, -5.4777e-01,\n",
            "          9.2147e-01,  1.9542e-01,  1.4805e+02,  4.9751e-02, -2.6729e-01,\n",
            "          7.4035e-01, -3.1358e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 71\n",
            " Current loss 0.6646537780761719\n",
            "\n",
            "tensor([[ 4.8613e-01,  1.0117e+00,  2.6674e-01, -6.5455e+01, -5.1101e-01,\n",
            "          9.6279e-01,  3.1404e-01,  1.4775e+02,  8.9320e-02, -2.4258e-01,\n",
            "          7.5405e-01, -2.4311e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 72\n",
            " Current loss 1.0362211465835571\n",
            "\n",
            "tensor([[ 5.1116e-01,  1.0357e+00,  3.3011e-01, -6.5527e+01, -5.1562e-01,\n",
            "          9.9306e-01,  4.0038e-01,  1.4787e+02,  1.1615e-01, -1.9143e-01,\n",
            "          7.8833e-01, -1.5857e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 73\n",
            " Current loss 0.9361101388931274\n",
            "\n",
            "tensor([[ 5.4903e-01,  1.0488e+00,  3.5711e-01, -6.5748e+01, -5.5756e-01,\n",
            "          1.0102e+00,  4.5285e-01,  1.4827e+02,  1.2868e-01, -1.2274e-01,\n",
            "          8.4077e-01, -6.5149e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 74\n",
            " Current loss 0.7197076082229614\n",
            "\n",
            "tensor([[ 5.9724e-01,  1.0498e+00,  3.5080e-01, -6.5960e+01, -6.2530e-01,\n",
            "          1.0115e+00,  4.7012e-01,  1.4861e+02,  1.2616e-01, -4.7694e-02,\n",
            "          9.0828e-01,  3.1039e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 75\n",
            " Current loss 0.8185422420501709\n",
            "\n",
            "tensor([[ 6.4133e-01,  1.0395e+00,  3.2384e-01, -6.6019e+01, -6.8694e-01,\n",
            "          9.9931e-01,  4.5716e-01,  1.4861e+02,  1.1378e-01,  8.8370e-03,\n",
            "          9.7001e-01,  1.0399e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 76\n",
            " Current loss 0.7605858445167542\n",
            "\n",
            "tensor([[ 6.8682e-01,  1.0177e+00,  2.7929e-01, -6.5967e+01, -7.4483e-01,\n",
            "          9.7530e-01,  4.2229e-01,  1.4835e+02,  9.4943e-02,  5.7225e-02,\n",
            "          1.0342e+00,  1.6753e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 77\n",
            " Current loss 0.5195485353469849\n",
            "\n",
            "tensor([[ 7.2863e-01,  9.8535e-01,  2.2103e-01, -6.5876e+01, -7.8963e-01,\n",
            "          9.4257e-01,  3.7270e-01,  1.4801e+02,  7.5059e-02,  9.5482e-02,\n",
            "          1.0950e+00,  2.1688e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 78\n",
            " Current loss 0.4432307183742523\n",
            "\n",
            "tensor([[ 7.6242e-01,  9.4385e-01,  1.5295e-01, -6.5838e+01, -8.1497e-01,\n",
            "          9.0451e-01,  3.1575e-01,  1.4779e+02,  5.9181e-02,  1.2336e-01,\n",
            "          1.1473e+00,  2.4871e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 79\n",
            " Current loss 0.4961927533149719\n",
            "\n",
            "tensor([[ 7.8602e-01,  8.9467e-01,  7.9806e-02, -6.5899e+01, -8.1770e-01,\n",
            "          8.6377e-01,  2.5694e-01,  1.4782e+02,  5.0400e-02,  1.4089e-01,\n",
            "          1.1876e+00,  2.6139e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 80\n",
            " Current loss 0.40309393405914307\n",
            "\n",
            "tensor([[ 7.9989e-01,  8.3925e-01,  7.7716e-03, -6.6035e+01, -7.9767e-01,\n",
            "          8.2190e-01,  1.9928e-01,  1.4805e+02,  4.9205e-02,  1.4756e-01,\n",
            "          1.2141e+00,  2.5506e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 81\n",
            " Current loss 0.2473459094762802\n",
            "\n",
            "tensor([[ 8.0627e-01,  7.7944e-01, -5.6221e-02, -6.6170e+01, -7.5784e-01,\n",
            "          7.7977e-01,  1.4384e-01,  1.4829e+02,  5.3817e-02,  1.4254e-01,\n",
            "          1.2268e+00,  2.3138e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 82\n",
            " Current loss 0.23773173987865448\n",
            "\n",
            "tensor([[ 8.0784e-01,  7.1796e-01, -1.0628e-01, -6.6228e+01, -7.0435e-01,\n",
            "          7.3829e-01,  9.1043e-02,  1.4839e+02,  6.1296e-02,  1.2582e-01,\n",
            "          1.2263e+00,  1.9351e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 83\n",
            " Current loss 0.2606464922428131\n",
            "\n",
            "tensor([[ 8.0631e-01,  6.5855e-01, -1.3941e-01, -6.6184e+01, -6.4584e-01,\n",
            "          6.9886e-01,  4.1621e-02,  1.4829e+02,  6.8784e-02,  9.9162e-02,\n",
            "          1.2140e+00,  1.4559e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 84\n",
            " Current loss 0.176277294754982\n",
            "\n",
            "tensor([[ 8.0197e-01,  6.0521e-01, -1.5626e-01, -6.6080e+01, -5.9189e-01,\n",
            "          6.6336e-01, -3.0978e-03,  1.4808e+02,  7.4293e-02,  6.6127e-02,\n",
            "          1.1913e+00,  9.2245e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 85\n",
            " Current loss 0.1193617433309555\n",
            "\n",
            "tensor([[ 7.9435e-01,  5.6139e-01, -1.5988e-01, -6.5987e+01, -5.5091e-01,\n",
            "          6.3371e-01, -4.1736e-02,  1.4790e+02,  7.6650e-02,  3.1081e-02,\n",
            "          1.1599e+00,  3.7854e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 86\n",
            " Current loss 0.16939698159694672\n",
            "\n",
            "tensor([[ 7.8329e-01,  5.2933e-01, -1.5374e-01, -6.5961e+01, -5.2873e-01,\n",
            "          6.1137e-01, -7.3509e-02,  1.4788e+02,  7.4973e-02, -2.1466e-03,\n",
            "          1.1217e+00, -1.3614e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 87\n",
            " Current loss 0.18652883172035217\n",
            "\n",
            "tensor([[ 7.6977e-01,  5.0979e-01, -1.4015e-01, -6.6005e+01, -5.2781e-01,\n",
            "          5.9712e-01, -9.8530e-02,  1.4802e+02,  6.8296e-02, -3.1075e-02,\n",
            "          1.0792e+00, -5.8735e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 88\n",
            " Current loss 0.13327598571777344\n",
            "\n",
            "tensor([[ 7.5584e-01,  5.0217e-01, -1.2007e-01, -6.6074e+01, -5.4713e-01,\n",
            "          5.9112e-01, -1.1755e-01,  1.4821e+02,  5.5734e-02, -5.4542e-02,\n",
            "          1.0352e+00, -9.4616e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 89\n",
            " Current loss 0.12596753239631653\n",
            "\n",
            "tensor([[ 7.4383e-01,  5.0481e-01, -9.4145e-02, -6.6109e+01, -5.8262e-01,\n",
            "          5.9312e-01, -1.3134e-01,  1.4833e+02,  3.7167e-02, -7.2114e-02,\n",
            "          9.9253e-01, -1.1925e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 90\n",
            " Current loss 0.15587782859802246\n",
            "\n",
            "tensor([[ 7.3692e-01,  5.1329e-01, -6.9927e-02, -6.6085e+01, -6.1888e-01,\n",
            "          6.0077e-01, -1.3834e-01,  1.4831e+02,  1.8517e-02, -8.1164e-02,\n",
            "          9.6149e-01, -1.2941e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 91\n",
            " Current loss 0.13393756747245789\n",
            "\n",
            "tensor([[ 7.3270e-01,  5.2644e-01, -4.4087e-02, -6.6021e+01, -6.5824e-01,\n",
            "          6.1396e-01, -1.4107e-01,  1.4819e+02, -2.1912e-03, -8.4944e-02,\n",
            "          9.3441e-01, -1.3066e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 92\n",
            " Current loss 0.09222819656133652\n",
            "\n",
            "tensor([[ 7.3050e-01,  5.4263e-01, -1.8925e-02, -6.5950e+01, -6.9598e-01,\n",
            "          6.3213e-01, -1.3906e-01,  1.4806e+02, -2.2768e-02, -8.3230e-02,\n",
            "          9.1166e-01, -1.2436e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 93\n",
            " Current loss 0.08924706280231476\n",
            "\n",
            "tensor([[ 7.2949e-01,  5.6042e-01,  3.4893e-03, -6.5907e+01, -7.2806e-01,\n",
            "          6.5444e-01, -1.3197e-01,  1.4799e+02, -4.1159e-02, -7.6139e-02,\n",
            "          8.9335e-01, -1.1222e-01]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 94\n",
            " Current loss 0.10378577560186386\n",
            "\n",
            "tensor([[ 7.2920e-01,  5.7861e-01,  2.1906e-02, -6.5908e+01, -7.5131e-01,\n",
            "          6.7971e-01, -1.1996e-01,  1.4802e+02, -5.5932e-02, -6.4394e-02,\n",
            "          8.7969e-01, -9.5954e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 95\n",
            " Current loss 0.08809458464384079\n",
            "\n",
            "tensor([[ 7.2975e-01,  5.9624e-01,  3.6051e-02, -6.5943e+01, -7.6368e-01,\n",
            "          7.0643e-01, -1.0379e-01,  1.4812e+02, -6.6480e-02, -4.9391e-02,\n",
            "          8.7107e-01, -7.7047e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 96\n",
            " Current loss 0.05914118140935898\n",
            "\n",
            "tensor([[ 7.3161e-01,  6.1262e-01,  4.6362e-02, -6.5984e+01, -7.6440e-01,\n",
            "          7.3281e-01, -8.4719e-02,  1.4824e+02, -7.2913e-02, -3.2944e-02,\n",
            "          8.6801e-01, -5.6757e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 97\n",
            " Current loss 0.05552064627408981\n",
            "\n",
            "tensor([[ 7.3517e-01,  6.2740e-01,  5.3458e-02, -6.6001e+01, -7.5408e-01,\n",
            "          7.5710e-01, -6.4236e-02,  1.4830e+02, -7.5758e-02, -1.6916e-02,\n",
            "          8.7085e-01, -3.6191e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 98\n",
            " Current loss 0.06226027011871338\n",
            "\n",
            "tensor([[ 7.4035e-01,  6.4062e-01,  5.7642e-02, -6.5982e+01, -7.3481e-01,\n",
            "          7.7783e-01, -4.3678e-02,  1.4828e+02, -7.5639e-02, -2.7268e-03,\n",
            "          8.7951e-01, -1.6355e-02]], grad_fn=<AddmmBackward0>)\n",
            "Epoch number 99\n",
            " Current loss 0.048304200172424316\n",
            "\n",
            "Best loss 0.048304200172424316\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAfbUlEQVR4nO3dfZBddZ3n8ff3PvdzHjqEkATShKgTHASNIQrroK4Q2N0JzjgsOCMZl5q4JZS6Ze0MzmwVs+NYpVszPlDrUIMSDY4LKsIQXRRjFkcRCTSCQMJDAklIh0A6SeepO923773f/eOc2zm5uZ3u9ENu9z2fV1VX3/s7D/d3OOF++vdwzjF3R0RE4i1R6wqIiEjtKQxERERhICIiCgMREUFhICIiQKrWFRir9vZ2X7RoUa2rISIyrTz11FP73H1OZfm0DYNFixbR2dlZ62qIiEwrZrazWrm6iURERGEgIiIKAxERQWEgIiIoDEREBIWBiIigMBAREWIYBuse28GPfvd6rashIjKlxC4M7nniNX78rMJARCQqdmHQnE1xpL9Q62qIiEwpsQuDllyKowMKAxGRqNiFQXMuzVG1DEREThC/MMimOKKWgYjICWIXBi25FEf6B2tdDRGRKSV2YdCcTdE/WGKwWKp1VUREpowRw8DMFprZI2a2xcw2m9mnw/K/NbPdZvZM+HNNZJvPmdk2M3vJzK6KlK8My7aZ2a2R8g4z2xSWf8/MMhN9oGUtueARDr3qKhIRGTKalkEB+Ky7LwVWADeb2dJw2Vfc/eLw5yGAcNn1wIXASuCfzCxpZkng68DVwFLghsh+vhTu6wKgB7hpgo7vJM3ZIAw0vVRE5LgRw8Dd97j7b8PXR4AXgPmn2GQVcK+7D7j7dmAbsDz82ebur7p7HrgXWGVmBnwAuC/cfh1w7VgPaCTlloGml4qIHHdaYwZmtgi4BNgUFt1iZs+a2VozmxmWzQd2RTbrCsuGK58NHHT3QkV5tc9fY2adZtbZ3d19OlUf0pxNA2oZiIhEjToMzKwZ+CHwGXc/DNwBLAYuBvYA/zgpNYxw9zvdfZm7L5sz56TnOY9K81DLQDOKRETKUqNZyczSBEHwXXe/H8Dd34ws/wbw4/DtbmBhZPMFYRnDlO8HZphZKmwdRNefcOVuIrUMRESOG81sIgPuAl5w9y9HyudFVvsw8Hz4ej1wvZllzawDWAI8ATwJLAlnDmUIBpnXu7sDjwAfCbdfDTw4vsMaXku2+pjB/b/t4p//7ZXJ+lgRkSltNC2Dy4CPAc+Z2TNh2V8TzAa6GHBgB/AJAHffbGbfB7YQzES62d2LAGZ2C/AwkATWuvvmcH9/BdxrZn8PPE0QPpNiqJuoomXwwNO7eeNQP5/4g8WT9dEiIlPWiGHg7o8CVmXRQ6fY5gvAF6qUP1RtO3d/lWC20aRrSCdJ2MndRD19eQYKuhBNROJpVGMG9cTMaM6efOfSnt5BCiWFgYjEU+xuRwHQkkuf1DI42Jcnr5aBiMRU7FoGUH6mwfGppflCid58Ea9hnUREaimWLYPKp50d7MsDaMxARGIrnmFQ8bSznr6glVAsOQXdzVREYiieYZBNnTC1tCdsGQDkFQYiEkOxDIOWXPqEp50djITBwKDCQETiJ6ZhUNkyOD6YrHEDEYmjWIZBczbFscHi0NPODp4QBsVaVUtEpGZiGwZw/GlnJ3QTqWUgIjEUzzCouHPpCQPICgMRiaFYhkFrxdPOetRNJCIxF8swKD/t7GikmyiZCO7Fp9lEIhJH8QyDoW6ioEXQ0zfIWS1ZQGMGIhJP8QyD7IljBgf78sxtzQEKAxGJp1iGQUtkzMDdOdg3yNlDYaAxAxGJn3iHQX+BIwMFCiXn7Da1DEQkvmIZBtGnnR3sDcYNzmrVmIGIxFcswyD6tLPyNQZD3USD6iYSkfiJZRjA8aedHTwWtAzKA8i6a6mIxFFswyBoGQwO3YpibrmbSNcZiEgMxTYMWsIH3PT0BmEwszFDJpnQmIGIxFJsw6A5Fzz6snwriraGNNlUQlNLRSSW4hsG4dPODvblac2lSCUTZNMJ3ahORGIptmHQkktxZCBoGcxsygCQTSXVTSQisRTbMCi3DHr68sxoDMIgk9KYgYjEU2zDoCWX5thgkX1H88xsDO5imk0ldJ2BiMRSbMOgfLO6rp4+ZjREwkAtAxGJofiGQeRpZ+VuomwqqQFkEYmlEcPAzBaa2SNmtsXMNpvZp8PyWWa2wcy2hr9nhuVmZreb2TYze9bM3hnZ1+pw/a1mtjpS/i4zey7c5nYzs8k42KiWsGUAwTUGUB4zUDeRiMTPaFoGBeCz7r4UWAHcbGZLgVuBje6+BNgYvge4GlgS/qwB7oAgPIDbgEuB5cBt5QAJ1/mLyHYrx39op1ZuGQDMbFI3kYjE24hh4O573P234esjwAvAfGAVsC5cbR1wbfh6FXC3Bx4HZpjZPOAqYIO7H3D3HmADsDJc1uruj7u7A3dH9jVpWnLpoddD3URphYGIxNNpjRmY2SLgEmATMNfd94SL3gDmhq/nA7sim3WFZacq76pSXu3z15hZp5l1dnd3n07VT9J8QjdRuWWgMQMRiadRh4GZNQM/BD7j7oejy8K/6H2C63YSd7/T3Ze5+7I5c+aMa18tuSpjBkmNGYhIPI0qDMwsTRAE33X3+8PiN8MuHsLfe8Py3cDCyOYLwrJTlS+oUj6poi2DGeWWgbqJRCSmRjObyIC7gBfc/cuRReuB8oyg1cCDkfIbw1lFK4BDYXfSw8CVZjYzHDi+Eng4XHbYzFaEn3VjZF+TpjETPO0MImMGqYRuYS0isZQaeRUuAz4GPGdmz4Rlfw18Efi+md0E7ASuC5c9BFwDbAP6gI8DuPsBM/s88GS43t+5+4Hw9SeBbwMNwE/Cn0lVftrZscEiTZkkUL43kbqJRCR+RgwDd38UGG7e/werrO/AzcPsay2wtkp5J/D2keoy0VpyabLpJOXLGrKpBCWHQrFEKhnb6/FEJIZG0zKoW83ZFB4Z986kggAYKCgMRCReYh0G7S0ZEpGLnbORMGjK1qpWIiJnXqzD4It/dBHRG19k08HYgcYNRCRuYh0GC2c1nvC+3DLQhWciEjfqGI+IjhmIiMSJwiAimwq7iXStgYjEjMIg4vgAssYMRCReFAYRWXUTiUhMKQwiMhpAFpGYUhhEDI0ZqJtIRGJGYRCRTaubSETiSWEQMTRmoNlEIhIzCoOIoW6iosJAROJFYRAxdNHZoMYMRCReFAYRmloqInGlMIhQGIhIXCkMIsyMTCqhqaUiEjsKgwrZZEIXnYlI7CgMKmTTCXUTiUjsKAwqZFNJXWcgIrGjMKiQ1ZiBiMSQwqBCJqUxAxGJH4VBhaBloDAQkXhRGFTIppLqJhKR2FEYVNBsIhGJI4VBhWwqccJsovW/e52P3bUJd69hrUREJpfCoEImlSAfuWvpb17Zz6+27uONw/01rJWIyORSGFSoHDPYd3QAgM27D9eqSiIik27EMDCztWa218yej5T9rZntNrNnwp9rIss+Z2bbzOwlM7sqUr4yLNtmZrdGyjvMbFNY/j0zy0zkAZ6uym6i/eUweF1hICL1azQtg28DK6uUf8XdLw5/HgIws6XA9cCF4Tb/ZGZJM0sCXweuBpYCN4TrAnwp3NcFQA9w03gOaLwqp5bu780DsGXPoVpVSURk0o0YBu7+S+DAKPe3CrjX3QfcfTuwDVge/mxz91fdPQ/cC6wyMwM+ANwXbr8OuPY0j2FCVV50tv9oEAZqGYhIPRvPmMEtZvZs2I00MyybD+yKrNMVlg1XPhs46O6FivKqzGyNmXWaWWd3d/c4qj688piBu9M/WOToQIHWXIqunmMc6huclM8UEam1sYbBHcBi4GJgD/CPE1ajU3D3O919mbsvmzNnzqR8RjaVoORQKPnQ4PG/WxJ81pY9ah2ISH0aUxi4+5vuXnT3EvANgm4ggN3AwsiqC8Ky4cr3AzPMLFVRXjPZ9PGnnZW7iN73lnYANr+ucQMRqU9jCgMzmxd5+2GgPNNoPXC9mWXNrANYAjwBPAksCWcOZQgGmdd7cCXXI8BHwu1XAw+OpU4TJZMMw2CwyP7eoGXw1rNbOaslyxaNG4hInUqNtIKZ3QNcAbSbWRdwG3CFmV0MOLAD+ASAu282s+8DW4ACcLO7F8P93AI8DCSBte6+OfyIvwLuNbO/B54G7pqwoxuDbDoJQL5YYl/YMpjdlGHpOa3qJhKRujViGLj7DVWKh/3CdvcvAF+oUv4Q8FCV8lc53s1Uc9lUuWVwvJtodnOGC89p5Vdb99E/WCQXBoaISL3QFcgVsqngi36gUGLf0QEaM0kaMymWzmujWHK2vnm0xjUUEZl4CoMKQy2DQpH9Rwdob84CcOE5rYAGkUWkPikMKmTCMMgXSuzvzTO7Obg7xrmzGmnOpnTxmYjUJYVBheMtg2AAeXZT0DJIJIzfm9eiQWQRqUsKgwrl2UTHu4mO3zfvwnPaeGHPYUolPdtAROqLwqBCuWXQPxh0E5XHDCDoKurLFzl0TLelEJH6ojCoUB4z2Hu4n2LJh8YMANoa0gAc7lcYiEh9URhUKLcMXj8UPNlsdqRl0BqGgVoGIlJvFAYVytcZ7D54DID2puMtg9ZccI3e4WOFkzcUEZnGFAYVyjeqez0Mg2jLoK1R3UQiUp8UBhXKN6orh0F0NlFrTt1EIlKfFAYVymMGe48MkDCY0RgJg/IAssJAROqMwqCCmZFJJXCHWU0ZkgkbWtaUSZJMmLqJRKTuKAyqKLcOylcfl5kZrbmUuolEpO4oDKoozyhqb8mctKytIa3ZRCJSdxQGVQzXMoBg3EAtAxGpNwqDKobCoPnklkFrLq0xAxGpOwqDKsq3pIjel6gs6CZSGIhIfVEYVFG+c+nspiotg4YUhzRmICJ1RmFQRTY5fMtA3UQiUo8UBlWUb0lRdcygIU2+UKJ/sHimqyUiMmkUBlVkTzFmoKuQRaQeKQyqKF9nUK1loGcaiEg9UhhUkUklaMwkacykTlpWvo21BpFFpJ6c/G0nvGNBG3356l/26iYSkXqkMKjizy/r4M8v66i6TN1EIlKP1E10mvRMAxGpRwqD09TaUH70pcJAROqHwuA0ZVNJcukEh/s1gCwi9WPEMDCztWa218yej5TNMrMNZrY1/D0zLDczu93MtpnZs2b2zsg2q8P1t5rZ6kj5u8zsuXCb283MmOJac2kO9allICL1YzQtg28DKyvKbgU2uvsSYGP4HuBqYEn4swa4A4LwAG4DLgWWA7eVAyRc5y8i21V+1pTT1qBbUohIfRkxDNz9l8CBiuJVwLrw9Trg2kj53R54HJhhZvOAq4AN7n7A3XuADcDKcFmruz/u7g7cHdnXlNWqMBCROjPWMYO57r4nfP0GMDd8PR/YFVmvKyw7VXlXlfKqzGyNmXWaWWd3d/cYqz5+evSliNSbcQ8gh3/R+wTUZTSfdae7L3P3ZXPmzDkTH1mVHn0pIvVmrGHwZtjFQ/h7b1i+G1gYWW9BWHaq8gVVyqc0dROJSL0ZaxisB8ozglYDD0bKbwxnFa0ADoXdSQ8DV5rZzHDg+Erg4XDZYTNbEc4iujGyrymrNRc87axUOiMNIhGRSTfi7SjM7B7gCqDdzLoIZgV9Efi+md0E7ASuC1d/CLgG2Ab0AR8HcPcDZvZ54Mlwvb9z9/Kg9CcJZiw1AD8Jf6a0toY0JYfefIGW8IpkEZHpbMQwcPcbhln0wSrrOnDzMPtZC6ytUt4JvH2kekwl5auQDx0bVBiISF3QFchjMHSzOg0ii0idUBiMQflmdRpEFpF6oTAYg/IzDXStgYjUC4XBGLTpATciUmcUBmNwvJtIYwYiUh8UBmPQkkthpm4iEakfCoMxSCSM5mxK3UQiUjcUBmPUmtMtKUSkfigMxii4WZ3CQETqg8JgjFobUrroTETqhsJgjFpzaQ0gi0jdUBiMkR59KSL1RGEwRq0aMxCROqIwGKO2hjS9+SKDxVKtqyIiMm4KgzFqzQW3sVbrQETqgcJgjN4ytwWAX7zUXeOaiIiMn8JgjN6zeDZLzmrmrke3EzzTR0Rk+lIYjJGZcdPlHWzZc5jHXz0w8gYiIlOYwmAcrr1kPrOaMtz16Ku1roqIyLgoDMYhl07yZ5eey8YX97J9X2+tqyMiMmYKg3H6s/ecRzqR4Fu/3l7rqoiIjJnCYJzOasnxhxefww86u3R7ChGZthQGE+DDl8zn2GCR53cfqnVVRETGRGEwARbPaQbgVY0biMg0pTCYAHNbszSkk2zvVhiIyPSkMJgAZsai9ia27zta66qIiIyJwmCCnN/exI79fbWuhojImCgMJkhHexOvHejTXUxFZFoaVxiY2Q4ze87MnjGzzrBslpltMLOt4e+ZYbmZ2e1mts3MnjWzd0b2szpcf6uZrR7fIdXGovYmiiVn1wG1DkRk+pmIlsH73f1id18Wvr8V2OjuS4CN4XuAq4El4c8a4A4IwgO4DbgUWA7cVg6Q6aSjvQlAVyKLyLQ0Gd1Eq4B14et1wLWR8rs98Dgww8zmAVcBG9z9gLv3ABuAlZNQr0l1vsJARKax8YaBAz8zs6fMbE1YNtfd94Sv3wDmhq/nA7si23aFZcOVn8TM1phZp5l1dndPrecIzGzKMKMxrTAQkWkpNc7tL3f33WZ2FrDBzF6MLnR3N7MJu9m/u98J3AmwbNmyKfcQgUWzmxQGIjItjatl4O67w997gQcI+vzfDLt/CH/vDVffDSyMbL4gLBuufNo5v11hICLT05jDwMyazKyl/Bq4EngeWA+UZwStBh4MX68HbgxnFa0ADoXdSQ8DV5rZzHDg+MqwbNrpaG9iz6F+juWLta6KiMhpGU830VzgATMr7+f/uPtPzexJ4PtmdhOwE7guXP8h4BpgG9AHfBzA3Q+Y2eeBJ8P1/s7dp+WjwzrmBIPIO/b38nvzWmtcGxGR0RtzGLj7q8A7qpTvBz5YpdyBm4fZ11pg7VjrMlUsmn18RpHCQESmE12BPIF0rYGITFcKgwnUlE0xtzXLq7p7qYhMMwqDCbZodhM79isMRGR6URhMsPPnaHqpiEw/CoMJ1tHexIHePAf78rWuiojIqCkMJlhHux6BKSLTj8Jggv3+/DYAfruzp8Y1EREZPYXBBDu7Lcf5c5r49bZ9ta6KiMioKQwmwXsXz+aJ7Qf01DMRmTYUBpPgssXt9OaLPNt16ITyx7btoy9fqFGtRESGpzCYBCvOnw0EX/5lv9t1kI9+cxP/44Hna1UtEZFhKQwmwcymDEvntfLYK/uHyu7+zU4A7n96N794ae9wm4qI1ITCYJJcdsFsnnqth/7BIgd68/zo2de5btkCFs9p4m8eeJ7eAXUXicjUoTCYJO9d3E6+UOKpnT38oHMX+UKJmy4/ny/98UW8fugY//Czl2pdRRGRIQqDSfLujlmkEsavtu7jXzbtZHnHLN56dgvLFs3iYyvO49uP7eDp13QtgohMDQqDSdKcTfGOhTP4zm92sOvAMW58z3lDy/77VW+lvTnLF3/y4vA7EBE5gxQGk+i9i2fTmy8ypyXLVReePVTekkvzySsWs2n7AR57RReniUjtKQwm0XsXtwNww/JzSSdP/E99w/Jzmdua5asbthI8BE5EpHYUBpPo0o5Z/K+PXMQn3nf+Scty6SQ3v/8Cnthx4IQpqCIitaAwmESJhHHdsoU0Zas/avo/v3sh89pyfGXDy2odiEhNKQxqKJtK8sn3X0Dnzh6++vOt/OKlvWzf16tgEJEzrvqfrHLGXLdsAd978jW+tnHrUNnHVpzH5699ew1rJSJxozCosWwqyY9uuZzuIwPsPNDHusd2cM8Tr/Ffr1jM/BkNta6eiMSEuommADPjrNYc7140i1uvfhsOrH10e62rJSIxojCYYhbMbOQ/XTSPe554jUN9g7WujojEhMJgClrzvsX05Yv8y6adJ5QXS87PNr/BR7/xOKv+96Os/93rFEsabBaR8dOYwRS09JxW3veWOXzr1zu46fIOegcKPPD0br7z+E527u/jnLYcjdkUn7rnab7685f5k3ctpCGdwMzIpRPMn9HIwlkNzGtrIJNS3ovIyGy6TmNctmyZd3Z21roak+axbfv46Dc3cdGCNl7Yc5jBonPJuTP4L5d1cPXbzyZhxk83v8HtG7fy4htHqu6jJZviL69+G3+6/FwSCTvDRyAiU5GZPeXuy04qVxhMTe7Odf/8G17p7uWPLpnPnyxbyFvPbqm63uFjBUrulNzpyxfp6jlGV08f//rMbn69bT/LO2bxpT++iI72phociYhMJVM+DMxsJfA1IAl8092/eKr16z0MAArFEmZGcox/1bs7P+js4vP/dwtH+gvMaspwVkuWOS1ZEmY4kEoYvz+/jfcuns3F587AHd483M8bh/rJF0uUhyTmtmZZNLuJXDo5tP98oUTCIJVUV5TIdDGlw8DMksDLwIeALuBJ4AZ33zLcNnEIg4ny5uF+7nuqi90Hj7H3cD/dR/PgDmYMDBZ5+c0jlBzSSWOwOPy/BzNYMLOBpBn7e/Mc6Q+e1taSTTGjKc3spizz2nKc3ZajIZ3k0LFBDvcXKJWcmU1pZjVmmNGYoSWXoiWXIptKMlAo0j9YYrBYoiGTpDGTpDGTojmboimbojGTpFhy8oVgHbNgKm7CjEwqQS6VIJdOUnRnsFBisOg4TsIMM0gnEmTTCTLJBAmzsAUVHE8yYSTC/YnExXBhMFUGkJcD29z9VQAzuxdYBQwbBjJ6c1tz3Pz+C4ZdfujYIE9sP8BTO3toziY5u62Bs1tz5MJBaXBeP9jPK91HeaW7F4DZTRlmNWVwh4PH8hzsG6T7yAAvv3mEf3u5m4FCibaGNG0NacygpzfPwWODTIG/PU6SShippJFOJkgljGLJcYdoVY0gDJOJoKXmzlCwuPvQugkLAiZozVUPGTOCdcywMLQSwwRSuTj4fMMIPtdhXP8tzY7Xrrzf6itWfXnGTdfALtf6VKdqLEf2409dTjaVHHnF0zBVwmA+sCvyvgu4tHIlM1sDrAE499xzz0zNYqCtIc2Hls7lQ0vnDrvOu84bdtFJyq3Nyv+BiyXn8LFBjg4UODpQoH+wSDaVJJdOkE4mODZYpC9fpG+gQG++yNGBQXoHiqTDL+rybcDL4yP5Qon+wRL9g0WSiaClkEokSBiUHIruFIolBgol8oUS7sGXcCJhuDvF0vF1CmHro+QefqEb0eqXPAiIYskpugf7Cb9Eqx1nMfJNHTbCTnhfCtcJQscplfyk/ZT/O5a/+D0sK9et2meXtzvVl2c0vCpDr9rnl+swKs7Ep8YU/ANiNLyi4tUit3Kd0TpFfI/ZVAmDUXH3O4E7IegmqnF1ZBjDfRElE8bMpgwzmzJnuEYiMpKpMvK3G1gYeb8gLBMRkTNgqoTBk8ASM+swswxwPbC+xnUSEYmNKdFN5O4FM7sFeJhgaulad99c42qJiMTGlAgDAHd/CHio1vUQEYmjqdJNJCIiNaQwEBERhYGIiCgMRESEKXJvorEws25g54grVtcO7JvA6kwHcTxmiOdxx/GYIZ7HPZZjPs/d51QWTtswGA8z66x2o6Z6FsdjhngedxyPGeJ53BN5zOomEhERhYGIiMQ3DO6sdQVqII7HDPE87jgeM8TzuCfsmGM5ZiAiIieKa8tAREQiFAYiIhKvMDCzlWb2kpltM7Nba12fyWJmC83sETPbYmabzezTYfksM9tgZlvD3zNrXdeJZmZJM3vazH4cvu8ws03hOf9eeIv0umJmM8zsPjN70cxeMLP31Pu5NrP/Fv7bft7M7jGzXD2eazNba2Z7zez5SFnVc2uB28Pjf9bM3nk6nxWbMDCzJPB14GpgKXCDmS2tba0mTQH4rLsvBVYAN4fHeiuw0d2XABvD9/Xm08ALkfdfAr7i7hcAPcBNNanV5Poa8FN3fxvwDoLjr9tzbWbzgU8By9z97QS3vb+e+jzX3wZWVpQNd26vBpaEP2uAO07ng2ITBsByYJu7v+rueeBeYFWN6zQp3H2Pu/82fH2E4MthPsHxrgtXWwdcW5saTg4zWwD8B+Cb4XsDPgDcF65Sj8fcBrwPuAvA3fPufpA6P9cEt99vMLMU0AjsoQ7Ptbv/EjhQUTzcuV0F3O2Bx4EZZjZvtJ8VpzCYD+yKvO8Ky+qamS0CLgE2AXPdfU+46A1gbo2qNVm+CvwlUArfzwYOunshfF+P57wD6Aa+FXaPfdPMmqjjc+3uu4F/AF4jCIFDwFPU/7kuG+7cjus7Lk5hEDtm1gz8EPiMux+OLvNgTnHdzCs2s/8I7HX3p2pdlzMsBbwTuMPdLwF6qegSqsNzPZPgr+AO4BygiZO7UmJhIs9tnMJgN7Aw8n5BWFaXzCxNEATfdff7w+I3y83G8PfeWtVvElwG/KGZ7SDoAvwAQV/6jLArAerznHcBXe6+KXx/H0E41PO5/vfAdnfvdvdB4H6C81/v57psuHM7ru+4OIXBk8CScMZBhmDAaX2N6zQpwr7yu4AX3P3LkUXrgdXh69XAg2e6bpPF3T/n7gvcfRHBuf1/7v6nwCPAR8LV6uqYAdz9DWCXmb01LPogsIU6PtcE3UMrzKwx/LdePua6PtcRw53b9cCN4ayiFcChSHfSyNw9Nj/ANcDLwCvA39S6PpN4nJcTNB2fBZ4Jf64h6EPfCGwFfg7MqnVdJ+n4rwB+HL4+H3gC2Ab8AMjWun6TcLwXA53h+f5XYGa9n2vgfwIvAs8D3wGy9XiugXsIxkUGCVqBNw13bgEjmDH5CvAcwWyrUX+WbkchIiKx6iYSEZFhKAxERERhICIiCgMREUFhICIiKAxERASFgYiIAP8f1DLzyHk32A0AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 241
        }
      ],
      "source": [
        "best_loss = np.inf\n",
        "loss_history = [] \n",
        "best_model_wts2 = copy.deepcopy(model2.state_dict())\n",
        "#iteration_number= 0\n",
        "\n",
        "# Iterate throught the epochs\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # Iterate over batches\n",
        "#    for i, (img0, img1, label) in enumerate(train_dataloader, 0):\n",
        "\n",
        "        # Send the images and labels to CUDA\n",
        " #       img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
        "  \n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Pass in the two images into the network and obtain two outputs\n",
        "        res = model2(x, y)\n",
        "        print(res)\n",
        "\n",
        "        # Pass the outputs of the networks and label into the loss function\n",
        "        loss = criterion(res, matrix.flatten())\n",
        "        # Calculate the backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "        scheduler.step() \n",
        "        # Every 10 batches print out the loss\n",
        "#        if i % 10 == 0 :\n",
        "        print(f\"Epoch number {epoch}\\n Current loss {loss.item()}\\n\")\n",
        "        #iteration_number += 10\n",
        "\n",
        "        if best_loss > loss:\n",
        "          best_loss = loss\n",
        "          best_model_wts2 = copy.deepcopy(model2.state_dict())\n",
        "\n",
        "        loss_history.append(loss.item())\n",
        "print(f'Best loss {best_loss}')\n",
        "\n",
        "plt.plot(range(num_epochs),loss_history)\n",
        "plt.show()\n",
        "model2.load_state_dict(best_model_wts2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model output check"
      ],
      "metadata": {
        "id": "bfm9tdyD5ltm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Printing the input and output\n",
        "print('the input')\n",
        "fig = plt.subplots(1,2)\n",
        "plt.subplot(1,2,1)\n",
        "x_to_print = x[0].numpy()\n",
        "x_to_print = x_to_print.transpose(1, 2, 0)\n",
        "plt.imshow(x_to_print[:,:,10])\n",
        "plt.subplot(1,2,2)\n",
        "y_to_print = y[0].numpy()\n",
        "y_to_print = y_to_print.transpose(1, 2, 0)\n",
        "plt.imshow(y_to_print[:,:,10])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I9AyuL4M3Wic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "21c7d4e5-ae07-4f61-93b7-710181716bd1"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the input\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1b99c5f990>"
            ]
          },
          "metadata": {},
          "execution_count": 174
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('the output of the model')\n",
        "\n",
        "result_matrix = model2(x, y)\n",
        "result_matrix = result_matrix.detach().numpy()\n",
        "print(y.sum())\n",
        "result_matrix_new = np.append(result_matrix,[0, 0, 0, 1]).reshape(4,4)\n",
        "result_matrix.shape\n",
        "x_nmp = x.detach().numpy()[0].transpose(1, 2, 0)\n",
        "print(x_nmp.sum())\n",
        "plt.imshow(x_nmp[:,:,10])\n",
        "x_new = affine_transform(x_nmp, result_matrix_new)\n",
        "print(x_new.sum())\n",
        "plt.imshow(x_new[:,:,10])\n",
        "\n",
        "m_check = np.array([[0.7431448, 0.6691306, 0., -65.964066 ],\n",
        " [-0.6691306, 0.7431448, 0., 148.15773],\n",
        " [0.,0., 1., 0.]])\n",
        "m_check = m_check.flatten()\n",
        "\n",
        "\n",
        "err = np.sum(np.power(np.subtract(m_check, result_matrix),2))/12\n",
        "\n",
        "y_nmp.shape\n",
        "\n",
        "mse = nn.MSELoss()\n",
        "m_check_tensor = torch.tensor(m_check)\n",
        "matrix_tensor = torch.tensor(result_matrix)\n",
        "print(mse(m_check_tensor, matrix_tensor))\n",
        "print(err)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spX7iqG1p4Cs",
        "outputId": "6cf8cda1-815b-4d03-8bd3-fa5d9277f5de"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2622.1957, dtype=torch.float64)\n",
            "2622.1956799693003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([1, 12])) that is different to the input size (torch.Size([12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.detach().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n66thVVP0BRm",
        "outputId": "c1db2c1b-41ce-4aa4-f89b-e0a578637c65"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7.4034929e-01,  6.4061707e-01,  5.7641596e-02, -6.5982307e+01,\n",
              "        -7.3480856e-01,  7.7782649e-01, -4.3678321e-02,  1.4828378e+02,\n",
              "        -7.5638726e-02, -2.7268361e-03,  8.7950772e-01, -1.6354546e-02]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_65 = torch.tensor(np.array([  1.0197,   0.2484,  -0.4615, -65.7467,  -0.9316,   0.5529,  -0.8590,\n",
        "         147.3966,  -0.2259,   0.2153,   1.0492,  -0.2639]))\n",
        "x_65.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AErWYTOj1nfg",
        "outputId": "5d7c6c1d-b3b3-4304-95aa-9dc99f07bdfb"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12])"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse(m_check_tensor, res)\n",
        "mse(m_check_tensor, x_65)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_iOo1dp0CHK",
        "outputId": "c6c741fd-fc68-44ca-e499-4c1207f6ef68"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7.4035e-01,  6.4062e-01,  5.7642e-02, -6.5982e+01, -7.3481e-01,\n",
              "          7.7783e-01, -4.3678e-02,  1.4828e+02, -7.5639e-02, -2.7268e-03,\n",
              "          8.7951e-01, -1.6355e-02]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res_matrix = x_65.detach().numpy()\n",
        "x_new = affine_transform(x_nmp, res_matrix.reshape(3,4))\n",
        "print(x_nmp.sum(), x_new.sum())\n",
        "plt.imshow(x_new[:,:,10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfEXWOes0ZuO",
        "outputId": "ebb4d501-c0df-4099-80e1-5552ccebe827"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "285767.1 62875.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nOYIYhkq0j3Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bfm9tdyD5ltm"
      ],
      "name": "NN_sharing_weights.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}